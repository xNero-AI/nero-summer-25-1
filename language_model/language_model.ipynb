{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de linguagem \n",
    "\n",
    "No tutorial de hoje, vamos explorar um pouco o conceito de modelo de linguagem na sua essência.\n",
    "Durante a última semana, usamos a API da OpenAI pra consumir o GPT, que é um LLM, mas ainda não foi aprofundado o que é de fato um modelo de linguagem, e o que eles conseguem e não conseguem fazer.\n",
    "\n",
    "#### O que é um modelo de linguagem?\n",
    "Imagina que eu te dou a tarefa de completar a seguinte frase:\n",
    "\n",
    "\"A cor do céu é ___\"\n",
    "\n",
    "Você provavelmente vai saber que a palavra que falta é azul. Não necessariamente porque você sabe os fenômenos físicos por trás disso, mas porque algo na sua memória te diz que azul é a resposta.\n",
    "\n",
    "Para treinar um modelo de linguagem utilizamos a mesma ideia. Nós forçamos o modelo a aprender a completar frases com os caracteres faltantes, até que em algum momento depois de ter ingerido muitos dados durante o treino, ele tenha a capacidade de gerar textos novos de acordo com o que ele aprendeu.\n",
    "\n",
    "#### Como funciona por dentro?\n",
    "\n",
    "Na prática, um modelo de linguagem trabalha com um vocabulário predefinido de tokens(que podem ser caracteres, palavras, ou partes de palavras). Cada token no vocabulário tem um índice único. Por exemplo, se nosso vocabulário tiver 200 tokens diferentes, o modelo precisa decidir qual desses 200 tokens deve vir em seguida em qualquer ponto do texto.\n",
    "\n",
    "#### Previsão de probabilidades\n",
    "\n",
    "Quando o modelo precisa prever o próximo token, ele gera um vetor de probabilidades com o mesmo tamanho do vocabulário(no nosso exemplo, 200 números). Cada número nesse vetor representa a probabilidade de cada token ser o próximo na sequência.\n",
    "Essas probabilidades:\n",
    "- são números entre 0 e 1\n",
    "- são normalizadas usando uma função chamada softmax, garantindo que todas as probabilidades somem 1\n",
    "- o token com a maior probabilidade é geralmente escolhido como a próxima previsão\n",
    "\n",
    "Usando o primeiro exemplo que eu dei, temos a frase \"A cor do céu é\", o modelo poderia gerar probabilidades como:\n",
    "- \"azul\": 0.85\n",
    "- \"vermelho': 0.05\n",
    "- \"verde\": 0.03\n",
    "- outros tokens de probabilidades menores \n",
    "\n",
    "Durante o aprendizado, o modelo ajusta essas probabilidades geradas para baterem com o que é esperado dos dados de treinamento. Cada vez que o modelo faz uma previsão errada, ele ajusta os parâmetros para aumentar a probabilidade do token correto e diminuir a dos errados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra: Emergencia de Conhecimento \n",
    "\n",
    "Uma das áreas que mais existe estudo atualmente sobre LLMs é como eles desenvolvem conhecimentos que vão além da simples previsão de tokens. Embora treinemos estes modelos com o objetivo específico de prever o próximo token em uma sequência, eles acabam emergindo com capacidades e conhecimentos muito mais sofisticados.\n",
    "\n",
    "Uma pesquisa recente da Anthropic trouxe algumas conclusões sobre como esse conhecimento se organiza dentro do modelo. Usando uma técnica chamada \"sparse autoencoder\", os pesquisadores conseguiram analisar as ativações internas do Claude 3 Sonnet e descobiram alguns pontos:\n",
    "    - O modelo aprende um espaço interno em que as informações similares se agrupam, algo similhante a um embedding interno\n",
    "    - Esse espaço não é caótico, mas sim organizado em grupos que realmente carregam descrições mesmo que abstratas sobre conceitos reais \n",
    "    - Foram encontrados pontos nesse espaço interno que correspondem a conceitos específicos, por exemplo, existe um ponto que representa a golden bridge gate\n",
    "    - Essas características sao ativadas consistentemente quando o modelo processa informações sobre a ponte, independente do idioma, ou seja, eles aprendem conceitos abstratos que não dependem do idioma que é processado.\n",
    "  \n",
    "Pra confirmar a hipótese, eles também fizeram alguns experimentos manipulando esse espaço. Foi identificado um ponto no espaço que corresppndia à caracterísitica neurociência. \n",
    "Com o modelo com as ativaçoes padrão, pergumtaram para o Clauda qual era sua ciência preferida, e ele respondeu que era física.\n",
    "Depois, modificaram o modelo para aumentar a força das ativações encontradas relacionadas a neurociência, e perguntaram a mesma coisa. A resposta agora era que a ciência preferida era neurociência.\n",
    "\n",
    "Embora ainda não é claro como os modelos aprendem esses padrões, apenas aprendendo a completar tokens, mas essa pesquisa serve como exemplo de como o conhecimento sobre domínios específicos surge nos modelos de linguagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ta c cpu\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "if tf.config.list_logical_devices(\"GPU\") != []:\n",
    "    print(\"ta c gpu\")\n",
    "else:\n",
    "    print(\"ta c cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_text):\n",
    "    lowercase_text = tf.strings.lower(input_text)\n",
    "    cleaned_text = tf.strings.regex_replace(lowercase_text, r\"[^a-z0-9 ]\", \"\")\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o texto\n",
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read().lower()\n",
    "\n",
    "print(content[:100]) #Printando os primeiros 100 caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui, criamos uma camada de vetorização de texto. Ela tem o papel de converter o texto em um vetor de inteiros. Por exemplo, a palavra \"hello\" pode ser convertida para [8, 5, 12, 12, 15], caso os índices das letras sejam a sua posição no alfabeto.\n",
    "text_vec_layer = keras.layers.TextVectorization(\n",
    "    split=\"character\", #Dividimos o texto em caracteres\n",
    "    standardize=\"lower\" #Padronizamos o texto para minúsculas\n",
    ")\n",
    "\n",
    "#Aqui, adaptamos a camada ao texto. Ela vai criar um índice inteiro para cada caractere usado no texto.\n",
    "text_vec_layer.adapt([content])\n",
    "encoded = text_vec_layer([content])[0] # usamos o [0] para pegar o tensor de índices. Utilizamos esse 0 porque a camada de vetorização retorna um tensor de índices, mesmo que só passemos um texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quando usamos a camada de vetorização, ela adiciona dois tokens especiais: um para o padding e outro para o out-of-vocabulary(caracteres não presentes na tabela de índices). Aqui, subtraímos 2 do número de índices para obter o número de tokens distintos.\n",
    "encoded -=2\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2  \n",
    "dataset_size = len(encoded)  # Numero de caracteres no texto = 1,782,290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 1782290)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparâmetros do dataset\n",
    "window_size = 128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, vamos começar a tratar os dados. Lembra que eu falei no início que o que um modelo de linguagem faz é tentar prever o próximo caractere dado um conjunto de caracteres anteriores? Pois bem, vamos criar um dataset que faz exatamente isso.\n",
    "# Como vimos, o texto é convertido em um vetor de inteiros. Vamos criar um dataset que: a cada passo, pega 128 caracteres e tenta prever o próximo caractere. Ou seja, o input é uma sequência de 128 caracteres e o output é o caractere seguinte.\n",
    "# Ou seja, o que o modelo vai tentar fazer é prever o próximo índice do vetor 'encoded' dado os 128 índices anteriores.\n",
    "# Como por exemplo, se a frase for \"hello, world\", o modelo vai tentar prever o caractere \"d\" dado \"hello, worl\".\n",
    "\n",
    "# Vamos criar um dataset que faz exatamente isso. Para isso, vamos usar a classe tf.data.Dataset. Vamos seguir os seguintes passos:\n",
    "# Suponha que 'encoded' seja [10, 11, 12, 13, 14] {NUMEROS ARBITRARIOS Q TO USANDO DE EXEMPLO},\n",
    "# e que window_size=2 (pra simplificar o entendimento)\n",
    "# No nosso caso real, window_size=128 e a lista 'encoded' é bem maior.\n",
    "\n",
    "# 1) from_tensor_slices -> transforma 'encoded' em uma sequência de indices na forma de um Dataset (1 caractere/índice por vez)\n",
    "#    exemplo:\n",
    "#    encoded = [10, 11, 12, 13, 14]\n",
    "#    -> Dataset com 5 exemplos: 10, 11, 12, 13, 14\n",
    "ds = tf.data.Dataset.from_tensor_slices(encoded)\n",
    "\n",
    "# 2) window -> agrupa a sequência em janelas de tamanho (window_size + 1)\n",
    "#    Como temos window_size=2 no nosso exemplo, fazemos window_size + 1 = 3\n",
    "#    Então cada janela terá 3 elementos\n",
    "#    Shift=1 significa que cada nova janela começa 1 elemento à frente da anterior\n",
    "#    Ou seja, teremos um dataset de datasets, onde cada dataset interno é uma janela\n",
    "#    exemplo:\n",
    "#    [10, 11, 12]\n",
    "#    [11, 12, 13]\n",
    "#    [12, 13, 14]\n",
    "ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "\n",
    "# 3) flat_map -> converte cada janela em um único tensor (em vez de um Dataset de Datasets)\n",
    "#    Isso vai agrupar cada janela (ex: [10, 11, 12]) em um tensor de shape (3,)\n",
    "#    exemplo:\n",
    "#    A janela [10, 11, 12] vira tf.Tensor([10, 11, 12])\n",
    "#    A janela [11, 12, 13] vira tf.Tensor([11, 12, 13])\n",
    "ds = ds.flat_map(lambda window: window.batch(window_size + 1))\n",
    "\n",
    "# 4) shuffle -> embaralha as janelas, para que o modelo não veja tudo em sequência exata\n",
    "#    exemplo:\n",
    "#    As janelas [10, 11, 12], [11, 12, 13], [12, 13, 14]\n",
    "#    podem ser apresentadas em ordem aleatória\n",
    "ds = ds.shuffle(100_000, seed=42)\n",
    "\n",
    "# 5) batch -> agrupa várias janelas em um lote (batch).\n",
    "#    No nosso caso, batch_size=32 no código real, mas no exemplo seria\n",
    "#    se tivéssemos mais janelas, agruparíamos X janelas em cada batch.\n",
    "#    exemplo:\n",
    "#    Se tivéssemos 96 janelas e batch_size=32,\n",
    "#    teríamos 3 batches, cada um com 32 janelas.\n",
    "ds = ds.batch(batch_size)\n",
    "\n",
    "# 6) map -> separa cada janela em (X, y). X é todos os caracteres MENOS o último,\n",
    "#    y é todos os caracteres MENOS o primeiro. Isso é para termos pares\n",
    "#    \"caractere atual -> próximo caractere\"\n",
    "#    exemplo (continuando):\n",
    "#    Se a janela for [10, 11, 12], então:\n",
    "#         X = [10, 11]\n",
    "#         y = [11, 12]\n",
    "#    Ou seja, \"dado 10, preveja 11; dado 11, preveja 12\"\n",
    "ds = ds.map(lambda window: (window[:, :-1], window[:, 1:]))\n",
    "\n",
    "# 7) prefetch -> melhorar a perfomance (carrega lotes futuros em paralelo)\n",
    "#    Não altera logicamente os dados, só otimiza a velocidade\n",
    "ds = ds.prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128) (32, 128)\n",
      "tf.Tensor(\n",
      "[ 0  1 12  1 24  1  0  8  1 10  3  5  1  7  3 16 13  3  0  4  3  8 20  1\n",
      "  7  3  5  0  7  2  4 22  1 28 29  4  2  0  7  1  0 19 11  6 10  2  5  1\n",
      " 17 17 17 13  2 14  1  0  3  0  2 33 12  6  9  1 16  0 12  3 10  0 21  2\n",
      "  4  9  3  0 12  1 14 12 11 14  1  7  3 32 13  8  1  0 12  1 24  2 26  1\n",
      "  0 14 20  2  0 14  1  8 26  1  0 14  2 18  2 10  2  8  9  2 13  3  0  1\n",
      "  7  1 10  1  8  9  6  8], shape=(128,), dtype=int64) tf.Tensor(\n",
      "[ 1 12  1 24  1  0  8  1 10  3  5  1  7  3 16 13  3  0  4  3  8 20  1  7\n",
      "  3  5  0  7  2  4 22  1 28 29  4  2  0  7  1  0 19 11  6 10  2  5  1 17\n",
      " 17 17 13  2 14  1  0  3  0  2 33 12  6  9  1 16  0 12  3 10  0 21  2  4\n",
      "  9  3  0 12  1 14 12 11 14  1  7  3 32 13  8  1  0 12  1 24  2 26  1  0\n",
      " 14 20  2  0 14  1  8 26  1  0 14  2 18  2 10  2  8  9  2 13  3  0  1  7\n",
      "  1 10  1  8  9  6  8  3], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# printando um batch com um exemplo\n",
    "for X_batch, y_batch in ds.take(1):\n",
    "    print(X_batch.shape, y_batch.shape)\n",
    "    print(X_batch[0], y_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, window_size=128, batch_size=32, seed=42, shuffle=False, target='all_window'):\n",
    "    \"\"\" Aqui, modularizando o código acima em uma função \"\"\"\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence) # Fatia o ds em janelas de tamanho window_size\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True) # Você pode visualizar com um .as_numpy_iterator() e colocar num loop com .take(1)\n",
    "    ds = ds.flat_map(lambda window: window.batch(window_size + 1)) # Transforma cada janela em um tensor\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    if target == 'all_window':\n",
    "        ds = ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
    "    elif target == 'last_char':\n",
    "        ds = ds.map(lambda window: (window[:, :-1], window[:, -1])).prefetch(1)\n",
    "    else:\n",
    "        raise ValueError('target must be \"all_window\" or \"last_char\"')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar os datasets de treino, validação e teste\n",
    "window_size = 128\n",
    "train_set = to_dataset(encoded[:1_000_000], window_size=window_size, shuffle=True, seed=42)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], window_size=window_size)\n",
    "test_set = to_dataset(encoded[1_060_000:], window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f.random.set_seed(42)  # extra code – reproducilidade\n",
    "\n",
    "#Aqui, nós criamos o modelo: uma camada de embeddings, que vai mapear os índices dos caracteres para vetores de tamanho 16. Depois, temos uma camada de convolução 1D com 32 filtros e kernel_size=3. A seguir, temos uma camada de GRU com 128 unidades. Por fim, temos uma camada densa com ativação softmax, que vai prever o próximo caractere. A saída da última camada é um vetor de tamanho n_tokens, que é o número de caracteres distintos no texto, cada posição do vetor representa a probabilidade do caractere ser o próximo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.Conv1D(32, kernel_size=3, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(seq, delta=2):\n",
    "    \"\"\" \n",
    "        Aqui, decodificamos a sequência de índices para texto.\n",
    "        Usa a camada de vetorização para mapear os índices para caracteres, ou seja, o inverso do que a camada de vetorização faz.\n",
    "        seq: sequência de índices\n",
    "        delta: deslocamento para mapear os índices para caracteres (default=2, pois tiramos os tokens especiais)\n",
    "    \"\"\"\n",
    "    output = np.array(text_vec_layer.get_vocabulary())[seq + delta]\n",
    "    new_output = []\n",
    "    for i in range(output.shape[0]):\n",
    "        phrase = \"\"\n",
    "        for j in range(output.shape[1]):\n",
    "            phrase += output[i, j]\n",
    "        new_output.append(phrase)\n",
    "    return np.array(new_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estilo\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['axes.facecolor'] = '#26262e' \n",
    "\n",
    "def print_multiple_generated(predicted_text, original_text, n=8):\n",
    "    print(\"--> Original text:\")\n",
    "    for i in range(n):\n",
    "        print(original_text[i])\n",
    "    print(\"\\n--> Generated text:\")\n",
    "    for i in range(n):\n",
    "        print(predicted_text[i])\n",
    "        \n",
    "def plot_loss(history, step):\n",
    "    plt.plot(list(range(len(history['loss']))), history['loss'], label='Training Loss')\n",
    "    plt.plot(list(range(len(history['loss']))), history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_accuracy(history, step):\n",
    "    plt.plot(list(range(len(history['accuracy']))), history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(list(range(len(history['accuracy']))), history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui, criamos um callback personalizado para logar o texto gerado a cada 1000 batches. O callback também loga o final de cada época.\n",
    "\n",
    "history = {\n",
    "            'text_base': 'A menina estava ',\n",
    "            'text_base_encoded': text_vec_layer(['A menina estava ']),\n",
    "            'list_predicted_text_base': [],\n",
    "        }\n",
    "\n",
    "class LogCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, history):\n",
    "        super().__init__()\n",
    "        self.history_ = history\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Final da época {epoch}, Loss: {logs['loss']}, Acc: {logs['accuracy']}\")\n",
    "    \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch % 1_000 == 0:\n",
    "            print(\"\")\n",
    "            print(f\"Final do lote {batch}, Loss do lote: {logs['loss']}\")\n",
    "            model = self.model\n",
    "            predicted_text = extend_text(\"A menina estava \", temperature=1.0)\n",
    "            print(\"\")\n",
    "            print(\"--> Original text: \", history['text_base'])\n",
    "            print(\"--> Generated text: \", predicted_text)\n",
    "            self.history_['list_predicted_text_base'].append(predicted_text)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"machado_model/machado_model.keras\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "\n",
    "\n",
    "# compilamos o modelo com a perda de sparse categorical entropy, o otimizador Nadam e a métrica de acurácia. Em seguida, treinamos o modelo com 10 épocas e o callback personalizado.\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# definimos a sequencial, em que o texto passa pela camada de vetorização, é subtraído 2 e então passa pelo modelo.\n",
    "shakespeare_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda X: X - 2),  # tira os tokens especiais\n",
    "    model\n",
    "])\n",
    "\n",
    "\n",
    "def extend_text(text, n_chars=50, temperature=1):\n",
    "    \"\"\" \n",
    "        Aqui, nós usamos o modelo para gerar texto.\n",
    "        Dado um texto inicial, o modelo preve o próximo caractere e adiciona ao texto.\n",
    "\n",
    "        A saida do modelo é um vetor de probabilidades para o próximo caractere, nós normalizamos essas probabilidades com a temperatura.\n",
    "        Quanto maior a temperatura, mais aleatório o texto gerado será.\n",
    "        Depois, usamos tf.random.categorical para amostrar o próximo caractere, ou seja, escolher um caractere aleatório baseado nas probabilidades, o que muito provavelmente vai ser o caractere com maior probabilidade.\n",
    "        Depois, obtemos o caractere correspondente ao índice amostrado e adicionamos ao texto.\n",
    "        Faremos isso n_chars vezes, gerando um texto de n_chars caracteres.\n",
    "    \"\"\"\n",
    "    for _ in range(n_chars):\n",
    "        input_data = tf.constant([text], dtype=tf.string)\n",
    "        y_proba = shakespeare_model.predict(input_data, verbose=0)[0, -1:]\n",
    "        rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "        char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0].numpy()\n",
    "        next_char = text_vec_layer.get_vocabulary()[char_id + 2]\n",
    "        text += next_char\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 1.8213555812835693\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava se\n",
      "felita na págio\n",
      "terrível artustes como\n",
      "quãe era\n",
      "\n",
      "   1000/Unknown \u001b[1m74s\u001b[0m 47ms/step - accuracy: 0.5161 - loss: 1.5810\n",
      "Final do lote 1000, Loss do lote: 1.5270321369171143\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava minh’alma,\n",
      "jou-lhes que minha mãe que se te proscr\n",
      "\n",
      "   2000/Unknown \u001b[1m121s\u001b[0m 47ms/step - accuracy: 0.5262 - loss: 1.5456\n",
      "Final do lote 2000, Loss do lote: 1.499700903892517\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava da man! — um digado\n",
      "sardima, e propa em que pariet\n",
      "\n",
      "   2999/Unknown \u001b[1m168s\u001b[0m 47ms/step - accuracy: 0.5311 - loss: 1.5283\n",
      "Final do lote 3000, Loss do lote: 1.4871782064437866\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que encontrar, político?\n",
      "olhará se flores. hausem \n",
      "\n",
      "   4000/Unknown \u001b[1m217s\u001b[0m 47ms/step - accuracy: 0.5344 - loss: 1.5168\n",
      "Final do lote 4000, Loss do lote: 1.4777566194534302\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava é do parpir;\n",
      ". humania sono a popuel do espírito p\n",
      "\n",
      "   5000/Unknown \u001b[1m309s\u001b[0m 56ms/step - accuracy: 0.5369 - loss: 1.5082\n",
      "Final do lote 5000, Loss do lote: 1.4707083702087402\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o sr. minha fei a aqui vem s. manom maço, e um lui\n",
      "\n",
      "   6000/Unknown \u001b[1m402s\u001b[0m 62ms/step - accuracy: 0.5390 - loss: 1.5014\n",
      "Final do lote 6000, Loss do lote: 1.4640072584152222\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava calo social. é a missão com o altou a luza.\n",
      "traços\n",
      "\n",
      "   7000/Unknown \u001b[1m495s\u001b[0m 67ms/step - accuracy: 0.5408 - loss: 1.4957\n",
      "Final do lote 7000, Loss do lote: 1.4586522579193115\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava concerdação do minha alma.\n",
      "\n",
      "os levos do sr.\n",
      "no jor\n",
      "\n",
      "   8000/Unknown \u001b[1m580s\u001b[0m 69ms/step - accuracy: 0.5423 - loss: 1.4908\n",
      "Final do lote 8000, Loss do lote: 1.4557517766952515\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava na durval\n",
      "(de dois caracteres, ser, e balente todo\n",
      "\n",
      "   9000/Unknown \u001b[1m644s\u001b[0m 69ms/step - accuracy: 0.5437 - loss: 1.4869\n",
      "Final do lote 9000, Loss do lote: 1.454969048500061\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava delicaçõe.\n",
      "não sofrir a jaria sentear\n",
      "duas aras da\n",
      "\n",
      "  10000/Unknown \u001b[1m736s\u001b[0m 71ms/step - accuracy: 0.5448 - loss: 1.4836\n",
      "Final do lote 10000, Loss do lote: 1.4528758525848389\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava amor acaba yada tinha,\n",
      "quem di provetana abela que\n",
      "\n",
      "  11000/Unknown \u001b[1m828s\u001b[0m 73ms/step - accuracy: 0.5458 - loss: 1.4807\n",
      "Final do lote 11000, Loss do lote: 1.4511877298355103\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de\n",
      "intelisas, e viu, quem e um conheiça em mecião,\n",
      "\n",
      "  11999/Unknown \u001b[1m890s\u001b[0m 72ms/step - accuracy: 0.5467 - loss: 1.4782\n",
      "Final do lote 12000, Loss do lote: 1.4481542110443115\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ao escrave e prometiva desde do povo, mas\n",
      "que, mál\n",
      "\n",
      "  13000/Unknown \u001b[1m937s\u001b[0m 70ms/step - accuracy: 0.5476 - loss: 1.4757\n",
      "Final do lote 13000, Loss do lote: 1.4449551105499268\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava um parece a. deve-se foi sobre a nossa peça. dirin\n",
      "\n",
      "  14000/Unknown \u001b[1m985s\u001b[0m 68ms/step - accuracy: 0.5484 - loss: 1.4735\n",
      "Final do lote 14000, Loss do lote: 1.4435369968414307\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava para os autos. nem ponto desconhéise.\n",
      "\n",
      "numa suas e\n",
      "\n",
      "  15000/Unknown \u001b[1m1048s\u001b[0m 68ms/step - accuracy: 0.5491 - loss: 1.4715\n",
      "Final do lote 15000, Loss do lote: 1.4439365863800049\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava à esfera pelos por um s. jas não é nútico\n",
      "de exciv\n",
      "\n",
      "  15999/Unknown \u001b[1m1121s\u001b[0m 68ms/step - accuracy: 0.5498 - loss: 1.4697\n",
      "Final do lote 16000, Loss do lote: 1.4419814348220825\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava enfim se desezemente hagatores da vivídioso:\n",
      "\n",
      "a cl\n",
      "\n",
      "  16999/Unknown \u001b[1m1168s\u001b[0m 67ms/step - accuracy: 0.5504 - loss: 1.4680\n",
      "Final do lote 17000, Loss do lote: 1.4409600496292114\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em caso de resolvido parácias mais\n",
      "flusto,\n",
      "não é a\n",
      "\n",
      "  18000/Unknown \u001b[1m1235s\u001b[0m 67ms/step - accuracy: 0.5509 - loss: 1.4665\n",
      "Final do lote 18000, Loss do lote: 1.440694808959961\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava um dade profinação de que lindueu recreadiatilis\n",
      "e\n",
      "\n",
      "  19000/Unknown \u001b[1m1306s\u001b[0m 67ms/step - accuracy: 0.5514 - loss: 1.4651\n",
      "Final do lote 19000, Loss do lote: 1.4400804042816162\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de trabalho.\n",
      "\n",
      ": outra compaino, suplindica litação\n",
      "\n",
      "  20000/Unknown \u001b[1m1398s\u001b[0m 69ms/step - accuracy: 0.5519 - loss: 1.4639\n",
      "Final do lote 20000, Loss do lote: 1.4398106336593628\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava aceição o certigência; o pútio reconheci? a\n",
      "fala, \n",
      "\n",
      "  20999/Unknown \u001b[1m1468s\u001b[0m 69ms/step - accuracy: 0.5523 - loss: 1.4627\n",
      "Final do lote 21000, Loss do lote: 1.4401297569274902\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava e pintura de s. 9.°.\n",
      "— também um nação celista pes\n",
      "\n",
      "  22000/Unknown \u001b[1m1518s\u001b[0m 68ms/step - accuracy: 0.5527 - loss: 1.4617\n",
      "Final do lote 22000, Loss do lote: 1.4415775537490845\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em ele apátio no alma ejamem, para deste artez, e\n",
      "\n",
      "\n",
      "  22999/Unknown \u001b[1m1566s\u001b[0m 67ms/step - accuracy: 0.5530 - loss: 1.4609\n",
      "Final do lote 23000, Loss do lote: 1.4433023929595947\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava para que faria de v. excia. se os\n",
      "mão apritarias d\n",
      "\n",
      "  24000/Unknown \u001b[1m1615s\u001b[0m 66ms/step - accuracy: 0.5533 - loss: 1.4602\n",
      "Final do lote 24000, Loss do lote: 1.4444106817245483\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava aos casos visitar,\n",
      "claria se os ato\n",
      "viúvoles já va\n",
      "\n",
      "  25000/Unknown \u001b[1m1716s\u001b[0m 68ms/step - accuracy: 0.5536 - loss: 1.4596\n",
      "Final do lote 25000, Loss do lote: 1.4451647996902466\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava com inventarão aparição garantido de possam, já fe\n",
      "\n",
      "  26000/Unknown \u001b[1m1812s\u001b[0m 69ms/step - accuracy: 0.5538 - loss: 1.4590\n",
      "Final do lote 26000, Loss do lote: 1.4452344179153442\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o tocorada. \n",
      "\n",
      "\n",
      "dilichiça, molinhar não cena, que j\n",
      "\n",
      "  27000/Unknown \u001b[1m1907s\u001b[0m 70ms/step - accuracy: 0.5540 - loss: 1.4585\n",
      "Final do lote 27000, Loss do lote: 1.444894552230835\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava na coisa merecem despeja-se. dedicam na armaio dal\n",
      "\n",
      "  28000/Unknown \u001b[1m2002s\u001b[0m 71ms/step - accuracy: 0.5542 - loss: 1.4580\n",
      "Final do lote 28000, Loss do lote: 1.4441661834716797\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava aparetaria subens da consii entre extam o\n",
      "drama. d\n",
      "\n",
      "  29000/Unknown \u001b[1m2094s\u001b[0m 71ms/step - accuracy: 0.5544 - loss: 1.4575\n",
      "Final do lote 29000, Loss do lote: 1.4428677558898926\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava consitam eiro de muitos betosias, de mulher os con\n",
      "\n",
      "  30000/Unknown \u001b[1m2186s\u001b[0m 72ms/step - accuracy: 0.5546 - loss: 1.4570\n",
      "Final do lote 30000, Loss do lote: 1.440789818763733\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava não ter cidadão,\n",
      "o certas diversas oncetóões para \n",
      "\n",
      "  30999/Unknown \u001b[1m2264s\u001b[0m 72ms/step - accuracy: 0.5548 - loss: 1.4564\n",
      "Final do lote 31000, Loss do lote: 1.438382625579834\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o drama\n",
      "fresca que o supercito por 15580 a fresca \n",
      "\n",
      "  31246/Unknown \u001b[1m2278s\u001b[0m 72ms/step - accuracy: 0.5549 - loss: 1.4563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gugu1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final da época 0, Loss: 1.4377723932266235, Acc: 0.5614280104637146\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2305s\u001b[0m 73ms/step - accuracy: 0.5549 - loss: 1.4563 - val_accuracy: 0.5110 - val_loss: 1.6662\n",
      "Epoch 2/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 2.0438084602355957\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava e dramática. iludivedo esposar na transição em, di\n",
      "\n",
      "\u001b[1m  999/31246\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24:05\u001b[0m 48ms/step - accuracy: 0.4883 - loss: 1.6952\n",
      "Final do lote 1000, Loss do lote: 1.5996482372283936\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava as vitórias poedas\n",
      "diante;\n",
      "nuar como abagar, e nas\n",
      "\n",
      "\u001b[1m 1999/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23:38\u001b[0m 48ms/step - accuracy: 0.5032 - loss: 1.6328\n",
      "Final do lote 2000, Loss do lote: 1.5501521825790405\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava alma gienlão vento de beijador socia,\n",
      "e que un rec\n",
      "\n",
      "\u001b[1m 3000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23:01\u001b[0m 49ms/step - accuracy: 0.5109 - loss: 1.6008\n",
      "Final do lote 3000, Loss do lote: 1.5243395566940308\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que era esse amor!\n",
      "se dirmite da porta dela os rua\n",
      "\n",
      "\u001b[1m 4000/31246\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25:13\u001b[0m 56ms/step - accuracy: 0.5163 - loss: 1.5793\n",
      "Final do lote 4000, Loss do lote: 1.50615394115448\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava do pari;\n",
      "e mais que tou situo novas compradados de\n",
      "\n",
      "\u001b[1m 5000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27:36\u001b[0m 63ms/step - accuracy: 0.5205 - loss: 1.5632\n",
      "Final do lote 5000, Loss do lote: 1.4912277460098267\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em ordem entranda dessa lantas teus!\n",
      "e as leis, ai\n",
      "\n",
      "\u001b[1m 6000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:37\u001b[0m 68ms/step - accuracy: 0.5240 - loss: 1.5500\n",
      "Final do lote 6000, Loss do lote: 1.4772266149520874\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava um cabeça-lhe repisso e canto\n",
      "de que est pelisto, \n",
      "\n",
      "\u001b[1m 7000/31246\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:28\u001b[0m 70ms/step - accuracy: 0.5271 - loss: 1.5387\n",
      "Final do lote 7000, Loss do lote: 1.4648983478546143\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava e pequenerque é fatal. poderá mais um drama derrad\n",
      "\n",
      "\u001b[1m 8000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:23\u001b[0m 73ms/step - accuracy: 0.5298 - loss: 1.5288\n",
      "Final do lote 8000, Loss do lote: 1.455165982246399\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava então do concerto é uma palavra aludou em patidade\n",
      "\n",
      "\u001b[1m 9000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27:59\u001b[0m 76ms/step - accuracy: 0.5323 - loss: 1.5203\n",
      "Final do lote 9000, Loss do lote: 1.447949767112732\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a revolução começam à flor efeito; mas — dam consi\n",
      "\n",
      "\u001b[1m10000/31246\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m27:18\u001b[0m 77ms/step - accuracy: 0.5344 - loss: 1.5126\n",
      "Final do lote 10000, Loss do lote: 1.4405218362808228\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava desascou-io, puro. (em um rosinha no banhorio\n",
      "diss\n",
      "\n",
      "\u001b[1m11000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m26:07\u001b[0m 77ms/step - accuracy: 0.5364 - loss: 1.5058\n",
      "Final do lote 11000, Loss do lote: 1.434183120727539\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em camito se ter sua há literalo à motivo de amor,\n",
      "\n",
      "\u001b[1m12000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m25:31\u001b[0m 80ms/step - accuracy: 0.5383 - loss: 1.4995\n",
      "Final do lote 12000, Loss do lote: 1.427180528640747\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava continuar talvez; em esforo de jorgevadas de uma t\n",
      "\n",
      "\u001b[1m13000/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m24:33\u001b[0m 81ms/step - accuracy: 0.5400 - loss: 1.4937\n",
      "Final do lote 13000, Loss do lote: 1.420461893081665\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava com que não é anjlumece,\n",
      "difícil\n",
      "que viqueia\n",
      "do im\n",
      "\n",
      "\u001b[1m14000/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m23:25\u001b[0m 81ms/step - accuracy: 0.5416 - loss: 1.4883\n",
      "Final do lote 14000, Loss do lote: 1.4159440994262695\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava à carta de\n",
      "josé  facilmente o desebre, \n",
      "desagrando\n",
      "\n",
      "\u001b[1m15000/31246\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m22:17\u001b[0m 82ms/step - accuracy: 0.5430 - loss: 1.4834\n",
      "Final do lote 15000, Loss do lote: 1.4134998321533203\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava não é impercentes, surva desmento. não apoder é o \n",
      "\n",
      "\u001b[1m16000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21:06\u001b[0m 83ms/step - accuracy: 0.5444 - loss: 1.4789\n",
      "Final do lote 16000, Loss do lote: 1.409671664237976\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava à lei. represente o\n",
      "coração, cada companhia coisa,\n",
      "\n",
      "\u001b[1m17000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19:51\u001b[0m 84ms/step - accuracy: 0.5456 - loss: 1.4748\n",
      "Final do lote 17000, Loss do lote: 1.407097339630127\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ie o da\n",
      "verdade, nela consolam que representação? \n",
      "\n",
      "\u001b[1m18000/31246\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18:35\u001b[0m 84ms/step - accuracy: 0.5467 - loss: 1.4710\n",
      "Final do lote 18000, Loss do lote: 1.4055571556091309\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava cimado remonsão que se triunfo\n",
      "ouvia sentia de san\n",
      "\n",
      "\u001b[1m19000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m17:16\u001b[0m 85ms/step - accuracy: 0.5478 - loss: 1.4675\n",
      "Final do lote 19000, Loss do lote: 1.4039658308029175\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava direi a francesa e que não prestejo, m j. sei perf\n",
      "\n",
      "\u001b[1m19999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15:53\u001b[0m 85ms/step - accuracy: 0.5488 - loss: 1.4643\n",
      "Final do lote 20000, Loss do lote: 1.4029490947723389\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava nesta marchada\n",
      "boatoso, morto, que o espoção decla\n",
      "\n",
      "\u001b[1m21000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m14:25\u001b[0m 84ms/step - accuracy: 0.5497 - loss: 1.4613\n",
      "Final do lote 21000, Loss do lote: 1.402523398399353\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava não pertence a mulher scaneomo, a pruncipação de u\n",
      "\n",
      "\u001b[1m22000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13:04\u001b[0m 85ms/step - accuracy: 0.5505 - loss: 1.4587\n",
      "Final do lote 22000, Loss do lote: 1.4033302068710327\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de luz admifeita por peristos. pelas\n",
      "respontadas.\n",
      "\n",
      "\n",
      "\u001b[1m23000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11:42\u001b[0m 85ms/step - accuracy: 0.5512 - loss: 1.4563\n",
      "Final do lote 23000, Loss do lote: 1.4047911167144775\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava do ori, nova entre o como é o\n",
      "mesculade, enxade às\n",
      "\n",
      "\u001b[1m24000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10:18\u001b[0m 85ms/step - accuracy: 0.5519 - loss: 1.4542\n",
      "Final do lote 24000, Loss do lote: 1.4055192470550537\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a criação, que exrando encontrada\n",
      "caracelo foi\n",
      "fog\n",
      "\n",
      "\u001b[1m25000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8:55\u001b[0m 86ms/step - accuracy: 0.5525 - loss: 1.4522\n",
      "Final do lote 25000, Loss do lote: 1.4059940576553345\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava aquele desta fois os leitores. entre as questões d\n",
      "\n",
      "\u001b[1m26000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7:30\u001b[0m 86ms/step - accuracy: 0.5530 - loss: 1.4505\n",
      "Final do lote 26000, Loss do lote: 1.4058164358139038\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava era recisitar o dr. sempre aquele sobre as melhoni\n",
      "\n",
      "\u001b[1m27000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6:06\u001b[0m 86ms/step - accuracy: 0.5535 - loss: 1.4488\n",
      "Final do lote 27000, Loss do lote: 1.405354619026184\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a dar a coisa os\n",
      "impressões na sessão é com propós\n",
      "\n",
      "\u001b[1m28000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4:40\u001b[0m 86ms/step - accuracy: 0.5540 - loss: 1.4472\n",
      "Final do lote 28000, Loss do lote: 1.4045953750610352\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava mais\n",
      "roupa de moderuado conhece de ruíoras eleição\n",
      "\n",
      "\u001b[1m29000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3:14\u001b[0m 87ms/step - accuracy: 0.5545 - loss: 1.4457\n",
      "Final do lote 29000, Loss do lote: 1.4034581184387207\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em meu alma e ungrupida na\n",
      "h.\n",
      "j v.. ilunça felicid\n",
      "\n",
      "\u001b[1m30000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:48\u001b[0m 87ms/step - accuracy: 0.5549 - loss: 1.4443\n",
      "Final do lote 30000, Loss do lote: 1.401625156402588\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava se ainda notável calmalà por não eternar ou vista \n",
      "\n",
      "\u001b[1m31000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - accuracy: 0.5554 - loss: 1.4429\n",
      "Final do lote 31000, Loss do lote: 1.399427056312561\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava contrarema nenhum\n",
      "peros,\n",
      "onde os principal ainda o\n",
      "\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5555 - loss: 1.4425Final da época 1, Loss: 1.398832082748413, Acc: 0.5689460039138794\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2794s\u001b[0m 89ms/step - accuracy: 0.5555 - loss: 1.4425 - val_accuracy: 0.5175 - val_loss: 1.6355\n",
      "Epoch 3/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 1.9889540672302246\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava os\n",
      "reparanças me fazendo para os delestigos, leret\n",
      "\n",
      "\u001b[1m 1000/31246\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44:28\u001b[0m 88ms/step - accuracy: 0.4952 - loss: 1.6599\n",
      "Final do lote 1000, Loss do lote: 1.5687354803085327\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava nação\n",
      "mais logueste\n",
      "a pobre, e no escravo,\n",
      "graça q\n",
      "\n",
      "\u001b[1m 2000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44:00\u001b[0m 90ms/step - accuracy: 0.5100 - loss: 1.6002\n",
      "Final do lote 2000, Loss do lote: 1.5211368799209595\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava facilida\n",
      "por um gamenta, dorme e o teu prime antig\n",
      "\n",
      "\u001b[1m 3000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43:00\u001b[0m 91ms/step - accuracy: 0.5176 - loss: 1.5696\n",
      "Final do lote 3000, Loss do lote: 1.4963221549987793\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava uma nação\n",
      "e haviandons abram-se à esperante levial\n",
      "\n",
      "\u001b[1m 4000/31246\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42:40\u001b[0m 94ms/step - accuracy: 0.5230 - loss: 1.5490\n",
      "Final do lote 4000, Loss do lote: 1.4786866903305054\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava sútilo passaria\n",
      "esperal dá na dou popique o pantou\n",
      "\n",
      "\u001b[1m 4999/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41:47\u001b[0m 96ms/step - accuracy: 0.5271 - loss: 1.5335\n",
      "Final do lote 5000, Loss do lote: 1.464455008506775\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava vien de francheu que lançous público ao público, —\n",
      "\n",
      "\u001b[1m 6000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36:54\u001b[0m 88ms/step - accuracy: 0.5305 - loss: 1.5209\n",
      "Final do lote 6000, Loss do lote: 1.4512591361999512\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava atravenias.\n",
      "\n",
      "o maneiro, na ventura, econômica se d\n",
      "\n",
      "\u001b[1m 6999/31246\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33:08\u001b[0m 82ms/step - accuracy: 0.5335 - loss: 1.5100\n",
      "Final do lote 7000, Loss do lote: 1.4394556283950806\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava dão... embeio melhor do acham espersar de criado,\n",
      "\n",
      "\n",
      "\u001b[1m 7999/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30:13\u001b[0m 78ms/step - accuracy: 0.5361 - loss: 1.5006\n",
      "Final do lote 8000, Loss do lote: 1.430284023284912\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava aparece ao sobretudo e dizer\n",
      "condentar o artista.\n",
      "\n",
      "\n",
      "\u001b[1m 9000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27:43\u001b[0m 75ms/step - accuracy: 0.5385 - loss: 1.4924\n",
      "Final do lote 9000, Loss do lote: 1.4230549335479736\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava crescido acuradou. sabe-lhe o levar nessas páginas\n",
      "\n",
      "\u001b[1m10000/31246\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m25:37\u001b[0m 72ms/step - accuracy: 0.5407 - loss: 1.4851\n",
      "Final do lote 10000, Loss do lote: 1.4154208898544312\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ir não tem crer merecimento real desastribeiro tai\n",
      "\n",
      "\u001b[1m11000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23:43\u001b[0m 70ms/step - accuracy: 0.5426 - loss: 1.4784\n",
      "Final do lote 11000, Loss do lote: 1.408888816833496\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava calada a uma aperfo e possão.\n",
      "esa) que sim, henern\n",
      "\n",
      "\u001b[1m12000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m21:52\u001b[0m 68ms/step - accuracy: 0.5444 - loss: 1.4724\n",
      "Final do lote 12000, Loss do lote: 1.4019606113433838\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava era uma respontânito, e presidara e paixão num\n",
      "mis\n",
      "\n",
      "\u001b[1m13000/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m20:14\u001b[0m 67ms/step - accuracy: 0.5461 - loss: 1.4667\n",
      "Final do lote 13000, Loss do lote: 1.3954249620437622\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava filho; ocioso ungens da arte.\n",
      "\n",
      "é umástica. mas um \n",
      "\n",
      "\u001b[1m13999/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m18:44\u001b[0m 65ms/step - accuracy: 0.5477 - loss: 1.4614\n",
      "Final do lote 14000, Loss do lote: 1.3919157981872559\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a estas duplonderei serásios lantos emer produziu \n",
      "\n",
      "\u001b[1m14999/31246\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m17:19\u001b[0m 64ms/step - accuracy: 0.5491 - loss: 1.4568\n",
      "Final do lote 15000, Loss do lote: 1.3899989128112793\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava todos os artigos, como se era ocha rigo!\n",
      "mas em qu\n",
      "\n",
      "\u001b[1m15999/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m15:58\u001b[0m 63ms/step - accuracy: 0.5504 - loss: 1.4525\n",
      "Final do lote 16000, Loss do lote: 1.3862652778625488\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de partido de armadas.\n",
      "\n",
      "não és esposa d. lacordo? \n",
      "\n",
      "\u001b[1m17000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m14:40\u001b[0m 62ms/step - accuracy: 0.5516 - loss: 1.4485\n",
      "Final do lote 17000, Loss do lote: 1.3838921785354614\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o\n",
      "segundo aletuidade isto, tem\n",
      "pregreis de autores\n",
      "\n",
      "\u001b[1m18000/31246\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m13:27\u001b[0m 61ms/step - accuracy: 0.5527 - loss: 1.4449\n",
      "Final do lote 18000, Loss do lote: 1.3824083805084229\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava às mulheres.\n",
      "\n",
      "— eledadezes, amor grisidando fundo-\n",
      "\n",
      "\u001b[1m19000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m12:16\u001b[0m 60ms/step - accuracy: 0.5538 - loss: 1.4415\n",
      "Final do lote 19000, Loss do lote: 1.3808941841125488\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava urna todas as coisas malostados, e relógio sorrica\n",
      "\n",
      "\u001b[1m19999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m11:08\u001b[0m 59ms/step - accuracy: 0.5547 - loss: 1.4385\n",
      "Final do lote 20000, Loss do lote: 1.3797720670700073\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava foi familiaro.\n",
      "\n",
      "\n",
      "\n",
      "viveu que nos resultado o seu am\n",
      "\n",
      "\u001b[1m20999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m10:01\u001b[0m 59ms/step - accuracy: 0.5556 - loss: 1.4357\n",
      "Final do lote 21000, Loss do lote: 1.3796002864837646\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ambelle da dá-lo.\n",
      "\n",
      "duvida muitos enquantos ou aper\n",
      "\n",
      "\u001b[1m22000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m8:57\u001b[0m 58ms/step - accuracy: 0.5564 - loss: 1.4331\n",
      "Final do lote 22000, Loss do lote: 1.380496859550476\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava muito da horas dramáticas.\n",
      "\n",
      "não põe e para acha\n",
      "eu\n",
      "\n",
      "\u001b[1m23000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7:54\u001b[0m 58ms/step - accuracy: 0.5571 - loss: 1.4309\n",
      "Final do lote 23000, Loss do lote: 1.3817715644836426\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava educação dos ainda ablativas., as celessos, tem ex\n",
      "\n",
      "\u001b[1m24000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6:53\u001b[0m 57ms/step - accuracy: 0.5577 - loss: 1.4288\n",
      "Final do lote 24000, Loss do lote: 1.3825608491897583\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em\n",
      "mais precioos, creio das versas de lembrada. \n",
      "o\n",
      "\n",
      "\u001b[1m24999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5:53\u001b[0m 57ms/step - accuracy: 0.5583 - loss: 1.4270\n",
      "Final do lote 25000, Loss do lote: 1.3830876350402832\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava melhimento para os dias. ou refebe; mas totos, e s\n",
      "\n",
      "\u001b[1m26000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4:54\u001b[0m 56ms/step - accuracy: 0.5589 - loss: 1.4253\n",
      "Final do lote 26000, Loss do lote: 1.3830549716949463\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava servir, com a\n",
      "regente se\n",
      "arrilidare para fáceis es\n",
      "\n",
      "\u001b[1m26999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:56\u001b[0m 56ms/step - accuracy: 0.5594 - loss: 1.4238\n",
      "Final do lote 27000, Loss do lote: 1.3828142881393433\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ainda, e v. excia.\n",
      "locredita de calor sofre nunca.\n",
      "\n",
      "\u001b[1m28000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:00\u001b[0m 55ms/step - accuracy: 0.5598 - loss: 1.4223\n",
      "Final do lote 28000, Loss do lote: 1.3822518587112427\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava nos ricuonanças serrana auver e trabalhar, traduçã\n",
      "\n",
      "\u001b[1m29000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2:04\u001b[0m 55ms/step - accuracy: 0.5603 - loss: 1.4209\n",
      "Final do lote 29000, Loss do lote: 1.3812514543533325\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de sua pertence de\n",
      "entusiasmo. o teatro de exumar \n",
      "\n",
      "\u001b[1m29999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:08\u001b[0m 55ms/step - accuracy: 0.5607 - loss: 1.4195\n",
      "Final do lote 30000, Loss do lote: 1.3796041011810303\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava verdade, e sincerou que eu sinco; em sbsilver terá\n",
      "\n",
      "\u001b[1m31000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m13s\u001b[0m 55ms/step - accuracy: 0.5611 - loss: 1.4182\n",
      "Final do lote 31000, Loss do lote: 1.3776755332946777\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava e comum\n",
      "houver pertence é um colar no sr. castilho\n",
      "\n",
      "\u001b[1m31245/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5612 - loss: 1.4179Final da época 2, Loss: 1.377180576324463, Acc: 0.5739680528640747\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1768s\u001b[0m 56ms/step - accuracy: 0.5612 - loss: 1.4179 - val_accuracy: 0.5208 - val_loss: 1.6192\n",
      "Epoch 4/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 1.9644782543182373\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava d. teus tais, antonio, se os reinares, sentuarias \n",
      "\n",
      "\u001b[1m  999/31246\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25:25\u001b[0m 50ms/step - accuracy: 0.4998 - loss: 1.6386\n",
      "Final do lote 1000, Loss do lote: 1.5504953861236572\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava limpostos!\n",
      "ou ora um coração do fogo\n",
      "a, lança!\n",
      "que\n",
      "\n",
      "\u001b[1m 2000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31:48\u001b[0m 65ms/step - accuracy: 0.5138 - loss: 1.5811\n",
      "Final do lote 2000, Loss do lote: 1.5053006410598755\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava foi outrora bonita; é prosadro\n",
      "acompa voz e demani\n",
      "\n",
      "\u001b[1m 3000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36:05\u001b[0m 77ms/step - accuracy: 0.5212 - loss: 1.5518\n",
      "Final do lote 3000, Loss do lote: 1.4818181991577148\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava dorvição do desenvolvimento...\n",
      "dorre que se levant\n",
      "\n",
      "\u001b[1m 4000/31246\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37:53\u001b[0m 83ms/step - accuracy: 0.5263 - loss: 1.5321\n",
      "Final do lote 4000, Loss do lote: 1.4650417566299438\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava aquelas vitagem deste\n",
      "arg vivera! absemo; só nas h\n",
      "\n",
      "\u001b[1m 5000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37:26\u001b[0m 86ms/step - accuracy: 0.5302 - loss: 1.5173\n",
      "Final do lote 5000, Loss do lote: 1.450990915298462\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o leitor da mão.\n",
      "recenção de regi com suave os poe\n",
      "\n",
      "\u001b[1m 6000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36:28\u001b[0m 87ms/step - accuracy: 0.5336 - loss: 1.5050\n",
      "Final do lote 6000, Loss do lote: 1.4367502927780151\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava dessa noute batizador; com o harmando o fundador.\n",
      "\n",
      "\n",
      "\u001b[1m 7000/31246\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34:01\u001b[0m 84ms/step - accuracy: 0.5366 - loss: 1.4944\n",
      "Final do lote 7000, Loss do lote: 1.4246472120285034\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava e nem sabe:\n",
      "sancho o bons que a minha literatura t\n",
      "\n",
      "\u001b[1m 7999/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33:01\u001b[0m 85ms/step - accuracy: 0.5393 - loss: 1.4850\n",
      "Final do lote 8000, Loss do lote: 1.4155322313308716\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava cheia trateu ainda os braços da arte, mas, caiar-m\n",
      "\n",
      "\u001b[1m 8999/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29:53\u001b[0m 81ms/step - accuracy: 0.5416 - loss: 1.4769\n",
      "Final do lote 9000, Loss do lote: 1.408204436302185\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava se não estavo um teatro da noite.\n",
      "\n",
      "durval\n",
      "\n",
      "quero m\n",
      "\n",
      "\u001b[1m 9999/31246\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m27:28\u001b[0m 78ms/step - accuracy: 0.5438 - loss: 1.4697\n",
      "Final do lote 10000, Loss do lote: 1.4007067680358887\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava contriunça do\n",
      "raros.\n",
      "\n",
      "morreda clássico y alto)\n",
      "des\n",
      "\n",
      "\u001b[1m10999/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m25:06\u001b[0m 74ms/step - accuracy: 0.5458 - loss: 1.4631\n",
      "Final do lote 11000, Loss do lote: 1.394003987312317\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava força é, comédia!\n",
      "\n",
      "rosinha\n",
      "\n",
      "o aunir outro de luz d\n",
      "\n",
      "\u001b[1m12000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23:09\u001b[0m 72ms/step - accuracy: 0.5476 - loss: 1.4570\n",
      "Final do lote 12000, Loss do lote: 1.38692045211792\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ensadam o um drama da procurou efeito.\n",
      "\n",
      "não há pro\n",
      "\n",
      "\u001b[1m12999/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21:43\u001b[0m 71ms/step - accuracy: 0.5493 - loss: 1.4514\n",
      "Final do lote 13000, Loss do lote: 1.3803887367248535\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava deus.\n",
      "\n",
      "deste meirundigando-se ateno que o bater-se\n",
      "\n",
      "\u001b[1m13999/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m19:56\u001b[0m 69ms/step - accuracy: 0.5509 - loss: 1.4462\n",
      "Final do lote 14000, Loss do lote: 1.3764153718948364\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o temos anjos a\n",
      "totalia para de poso de francesa é\n",
      "\n",
      "\u001b[1m15000/31246\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m18:18\u001b[0m 68ms/step - accuracy: 0.5523 - loss: 1.4414\n",
      "Final do lote 15000, Loss do lote: 1.37424898147583\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava festável nes\n",
      "eferencia deixandora condentemos uma \n",
      "\n",
      "\u001b[1m16000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m16:48\u001b[0m 66ms/step - accuracy: 0.5536 - loss: 1.4371\n",
      "Final do lote 16000, Loss do lote: 1.3706508874893188\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a esses\n",
      "escreves e despede-se que ocioso por dem o\n",
      "\n",
      "\u001b[1m16999/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m15:23\u001b[0m 65ms/step - accuracy: 0.5548 - loss: 1.4332\n",
      "Final do lote 17000, Loss do lote: 1.3684898614883423\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a laberto.\n",
      "\n",
      "demais descansecisiarada\n",
      "de\n",
      "tambitação\n",
      "\n",
      "\u001b[1m17999/31246\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m14:02\u001b[0m 64ms/step - accuracy: 0.5560 - loss: 1.4295\n",
      "Final do lote 18000, Loss do lote: 1.36713707447052\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava do ardente; lhes recentes a poliado os anos, que s\n",
      "\n",
      "\u001b[1m18999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m12:45\u001b[0m 63ms/step - accuracy: 0.5570 - loss: 1.4262\n",
      "Final do lote 19000, Loss do lote: 1.3658713102340698\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava darei não se tem boa jastimona ir\n",
      "pareceburia e to\n",
      "\n",
      "\u001b[1m20000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m11:32\u001b[0m 62ms/step - accuracy: 0.5579 - loss: 1.4232\n",
      "Final do lote 20000, Loss do lote: 1.3649169206619263\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a pinturia, consugina para não convicdrão dinará u\n",
      "\n",
      "\u001b[1m21000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m10:22\u001b[0m 61ms/step - accuracy: 0.5588 - loss: 1.4204\n",
      "Final do lote 21000, Loss do lote: 1.3649184703826904\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava contra a íltini. do chora o nosso ensácida dirigo-\n",
      "\n",
      "\u001b[1m22000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m9:14\u001b[0m 60ms/step - accuracy: 0.5596 - loss: 1.4179\n",
      "Final do lote 22000, Loss do lote: 1.3658151626586914\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava etada? pela legitima só, bem adejá posteridades qu\n",
      "\n",
      "\u001b[1m23000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m8:08\u001b[0m 59ms/step - accuracy: 0.5603 - loss: 1.4156\n",
      "Final do lote 23000, Loss do lote: 1.3672196865081787\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava despego no deseju, que\n",
      "o inivilhel dos\n",
      "chafazies v\n",
      "\n",
      "\u001b[1m24000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7:04\u001b[0m 59ms/step - accuracy: 0.5609 - loss: 1.4136\n",
      "Final do lote 24000, Loss do lote: 1.3681660890579224\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que pela escola da prende uma\n",
      "escola de comédio, n\n",
      "\n",
      "\u001b[1m24999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6:02\u001b[0m 58ms/step - accuracy: 0.5615 - loss: 1.4118\n",
      "Final do lote 25000, Loss do lote: 1.3689252138137817\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava do dr. semana? é como escreva-lhe lírico, que elig\n",
      "\n",
      "\u001b[1m26000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5:01\u001b[0m 57ms/step - accuracy: 0.5621 - loss: 1.4102\n",
      "Final do lote 26000, Loss do lote: 1.3689860105514526\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava religiosa para o\n",
      "deputadão na vista.\n",
      "engano obra n\n",
      "\n",
      "\u001b[1m26999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4:01\u001b[0m 57ms/step - accuracy: 0.5626 - loss: 1.4087\n",
      "Final do lote 27000, Loss do lote: 1.3687993288040161\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava do chamores, como importante das algibeiras dada a\n",
      "\n",
      "\u001b[1m28000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:03\u001b[0m 56ms/step - accuracy: 0.5630 - loss: 1.4072\n",
      "Final do lote 28000, Loss do lote: 1.3683345317840576\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava livretório com v. s. tereza, e já menos flor de de\n",
      "\n",
      "\u001b[1m29000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2:05\u001b[0m 56ms/step - accuracy: 0.5635 - loss: 1.4059\n",
      "Final do lote 29000, Loss do lote: 1.3674606084823608\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava nem\n",
      "o aplicado,\n",
      "e farei uma pus nesse lética de no\n",
      "\n",
      "\u001b[1m30000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:09\u001b[0m 55ms/step - accuracy: 0.5639 - loss: 1.4046\n",
      "Final do lote 30000, Loss do lote: 1.3659716844558716\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava são cadindas recebismos de modernos do ilustre pel\n",
      "\n",
      "\u001b[1m30999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m13s\u001b[0m 55ms/step - accuracy: 0.5643 - loss: 1.4033\n",
      "Final do lote 31000, Loss do lote: 1.3641740083694458\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em v. excia.\n",
      "\n",
      "o missa é quando na confrandae dê gu\n",
      "\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5644 - loss: 1.4030Final da época 3, Loss: 1.363706111907959, Acc: 0.577049732208252\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1752s\u001b[0m 56ms/step - accuracy: 0.5644 - loss: 1.4030 - val_accuracy: 0.5214 - val_loss: 1.6130\n",
      "Epoch 5/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 1.9494041204452515\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava uma\n",
      "critueltas, daqui foi\n",
      "estes cabeçosos, tais as\n",
      "\n",
      "\u001b[1m 1000/31246\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:08\u001b[0m 40ms/step - accuracy: 0.5025 - loss: 1.6313\n",
      "Final do lote 1000, Loss do lote: 1.542497158050537\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a língua.\n",
      "netela sobre a fronte\n",
      "que to um pairam-s\n",
      "\n",
      "\u001b[1m 2000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:12\u001b[0m 41ms/step - accuracy: 0.5167 - loss: 1.5733\n",
      "Final do lote 2000, Loss do lote: 1.4965453147888184\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava com\n",
      "escrever pesada a pé,\n",
      "sou por um suspido de um\n",
      "\n",
      "\u001b[1m 2999/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:43\u001b[0m 42ms/step - accuracy: 0.5240 - loss: 1.5436\n",
      "Final do lote 3000, Loss do lote: 1.4725779294967651\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava se aquele, e mulherestem, vivo, brilhano salagro d\n",
      "\n",
      "\u001b[1m 4000/31246\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:08\u001b[0m 42ms/step - accuracy: 0.5291 - loss: 1.5236\n",
      "Final do lote 4000, Loss do lote: 1.455476999282837\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava da idéia purieta uma envio.\n",
      "para dão!\n",
      "e soubo e ma\n",
      "\n",
      "\u001b[1m 4999/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:34\u001b[0m 42ms/step - accuracy: 0.5331 - loss: 1.5085\n",
      "Final do lote 5000, Loss do lote: 1.4415398836135864\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava um dos cômicos\n",
      "todas a casta e anúncio, desegro,\n",
      "o\n",
      "\n",
      "\u001b[1m 6000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:55\u001b[0m 43ms/step - accuracy: 0.5364 - loss: 1.4962\n",
      "Final do lote 6000, Loss do lote: 1.4277687072753906\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que isso fugora as\n",
      "veutes das ordinais. as direçõe\n",
      "\n",
      "\u001b[1m 6999/31246\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:15\u001b[0m 43ms/step - accuracy: 0.5393 - loss: 1.4856\n",
      "Final do lote 7000, Loss do lote: 1.4157220125198364\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava com o folhetemo, a gentil e verdavem,\n",
      "aclátréel de\n",
      "\n",
      "\u001b[1m 7999/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:34\u001b[0m 43ms/step - accuracy: 0.5420 - loss: 1.4763\n",
      "Final do lote 8000, Loss do lote: 1.4078224897384644\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava do seu eleição, voltente acanhamento do reperção d\n",
      "\n",
      "\u001b[1m 9000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:54\u001b[0m 43ms/step - accuracy: 0.5443 - loss: 1.4683\n",
      "Final do lote 9000, Loss do lote: 1.4007103443145752\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava é, e ouvido-se a histo folhetim.\n",
      "\n",
      "talvez outra har\n",
      "\n",
      "\u001b[1m10000/31246\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:12\u001b[0m 43ms/step - accuracy: 0.5463 - loss: 1.4612\n",
      "Final do lote 10000, Loss do lote: 1.3934129476547241\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava anuncia; fez por vencer os\n",
      "ser oposição de\n",
      "pouco e\n",
      "\n",
      "\u001b[1m11000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m14:29\u001b[0m 43ms/step - accuracy: 0.5482 - loss: 1.4547\n",
      "Final do lote 11000, Loss do lote: 1.3870786428451538\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava irásel com a nossa\n",
      "onda para\n",
      "companhia da que a in\n",
      "\n",
      "\u001b[1m12000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m13:47\u001b[0m 43ms/step - accuracy: 0.5500 - loss: 1.4488\n",
      "Final do lote 12000, Loss do lote: 1.380286693572998\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava opinião.\n",
      "menos que não;\n",
      "!\n",
      "\n",
      "no caso mal da natureza\n",
      "\n",
      "\u001b[1m13000/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13:04\u001b[0m 43ms/step - accuracy: 0.5516 - loss: 1.4433\n",
      "Final do lote 13000, Loss do lote: 1.373772144317627\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava para pertencia pela missão casamento que esta a cr\n",
      "\n",
      "\u001b[1m14000/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12:22\u001b[0m 43ms/step - accuracy: 0.5531 - loss: 1.4382\n",
      "Final do lote 14000, Loss do lote: 1.3695337772369385\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o\n",
      "dever, sem\n",
      "couporos como conceito. cebendo até a\n",
      "\n",
      "\u001b[1m15000/31246\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11:39\u001b[0m 43ms/step - accuracy: 0.5545 - loss: 1.4335\n",
      "Final do lote 15000, Loss do lote: 1.3672860860824585\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava espero de certo da esqual os\n",
      "frades despriário dos\n",
      "\n",
      "\u001b[1m15999/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10:57\u001b[0m 43ms/step - accuracy: 0.5558 - loss: 1.4293\n",
      "Final do lote 16000, Loss do lote: 1.3635658025741577\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ao jardo a meu\n",
      "seu aliados sofejam à que falso fil\n",
      "\n",
      "\u001b[1m17000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10:13\u001b[0m 43ms/step - accuracy: 0.5570 - loss: 1.4253\n",
      "Final do lote 17000, Loss do lote: 1.3611706495285034\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ou acobente.\n",
      "salva, senhora ao poeta não quiser be\n",
      "\n",
      "\u001b[1m17999/31246\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9:30\u001b[0m 43ms/step - accuracy: 0.5581 - loss: 1.4217\n",
      "Final do lote 18000, Loss do lote: 1.3597612380981445\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava e que comeceu o que saiver?\n",
      "\n",
      "f velou os futuras, b\n",
      "\n",
      "\u001b[1m19000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8:47\u001b[0m 43ms/step - accuracy: 0.5591 - loss: 1.4184\n",
      "Final do lote 19000, Loss do lote: 1.358293056488037\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava lhe suponsão\n",
      "então...\n",
      "\n",
      "pedro alves\n",
      "\n",
      "princesso scav\n",
      "\n",
      "\u001b[1m19999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8:04\u001b[0m 43ms/step - accuracy: 0.5601 - loss: 1.4154\n",
      "Final do lote 20000, Loss do lote: 1.357375144958496\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de\n",
      "tornar à curso destis.\n",
      "\n",
      "cleuo apatecar um be de\n",
      "\n",
      "\u001b[1m20999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7:21\u001b[0m 43ms/step - accuracy: 0.5609 - loss: 1.4126\n",
      "Final do lote 21000, Loss do lote: 1.3571804761886597\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava com outra jornaas doutor do público, a filisa de —\n",
      "\n",
      "\u001b[1m21999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6:38\u001b[0m 43ms/step - accuracy: 0.5617 - loss: 1.4101\n",
      "Final do lote 22000, Loss do lote: 1.3580645322799683\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o vasto de g. s. pleio.\n",
      "\n",
      "o procurado que foi por s\n",
      "\n",
      "\u001b[1m23000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m5:55\u001b[0m 43ms/step - accuracy: 0.5624 - loss: 1.4079\n",
      "Final do lote 23000, Loss do lote: 1.3594144582748413\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ela compreendessa.\n",
      "\n",
      "conjetor só ao metingada; pelo\n",
      "\n",
      "\u001b[1m23999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5:12\u001b[0m 43ms/step - accuracy: 0.5630 - loss: 1.4059\n",
      "Final do lote 24000, Loss do lote: 1.3603261709213257\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em invento-lhe inferna. não sou das rua e barbaçõe\n",
      "\n",
      "\u001b[1m24999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4:29\u001b[0m 43ms/step - accuracy: 0.5636 - loss: 1.4041\n",
      "Final do lote 25000, Loss do lote: 1.3610559701919556\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava imereço, dois articheiros, as arriscuitosos, cabed\n",
      "\n",
      "\u001b[1m26000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3:46\u001b[0m 43ms/step - accuracy: 0.5641 - loss: 1.4024\n",
      "Final do lote 26000, Loss do lote: 1.3611937761306763\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava se tenta.\n",
      "aos sacrifuídos para\n",
      "outro\n",
      "difícia\n",
      "e art\n",
      "\n",
      "\u001b[1m26999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:03\u001b[0m 43ms/step - accuracy: 0.5646 - loss: 1.4009\n",
      "Final do lote 27000, Loss do lote: 1.3611464500427246\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava abrir de maio de 1863\n",
      "\n",
      "(o desejam muito a sua cena\n",
      "\n",
      "\u001b[1m28000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2:19\u001b[0m 43ms/step - accuracy: 0.5651 - loss: 1.3995\n",
      "Final do lote 28000, Loss do lote: 1.3607361316680908\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava entrar-me as produziram uma concorrência de distin\n",
      "\n",
      "\u001b[1m28999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:36\u001b[0m 43ms/step - accuracy: 0.5655 - loss: 1.3981\n",
      "Final do lote 29000, Loss do lote: 1.3599621057510376\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava uma sua confunário, é um resulta de sápio.\n",
      "também\n",
      "\n",
      "\n",
      "\u001b[1m29999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - accuracy: 0.5659 - loss: 1.3968\n",
      "Final do lote 30000, Loss do lote: 1.3585598468780518\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava levam a idéia faça para lhes e de\n",
      "litena.\n",
      "mas\n",
      "o si\n",
      "\n",
      "\u001b[1m31000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.5663 - loss: 1.3956\n",
      "Final do lote 31000, Loss do lote: 1.356890320777893\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o nosso túmulo.\n",
      "risette conselhonção\n",
      "em janeira o \n",
      "\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5664 - loss: 1.3953Final da época 4, Loss: 1.3564845323562622, Acc: 0.5786588788032532\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1375s\u001b[0m 44ms/step - accuracy: 0.5664 - loss: 1.3953 - val_accuracy: 0.5251 - val_loss: 1.6108\n",
      "Epoch 6/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 2.0216429233551025\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ares . .\n",
      "\n",
      "c'es ferro ao az aplerença.\n",
      "eu 1863, na \n",
      "\n",
      "\u001b[1m  999/31246\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:26\u001b[0m 41ms/step - accuracy: 0.5057 - loss: 1.6187\n",
      "Final do lote 1000, Loss do lote: 1.5324822664260864\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava por ventura;\n",
      "rebanta de dá-lo amarga ainda horreu \n",
      "\n",
      "\u001b[1m 1999/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:19\u001b[0m 42ms/step - accuracy: 0.5194 - loss: 1.5623\n",
      "Final do lote 2000, Loss do lote: 1.487980604171753\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava uma planta\n",
      "valiosa, um modo e me fez o ocasolado d\n",
      "\n",
      "\u001b[1m 2999/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:56\u001b[0m 42ms/step - accuracy: 0.5264 - loss: 1.5335\n",
      "Final do lote 3000, Loss do lote: 1.464596152305603\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o entrelou! — na jovea e toda à carta. o deste amo\n",
      "\n",
      "\u001b[1m 4000/31246\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:16\u001b[0m 42ms/step - accuracy: 0.5314 - loss: 1.5141\n",
      "Final do lote 4000, Loss do lote: 1.4477486610412598\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o sofai graciosa vazem e que\n",
      "a de escadeus! à são \n",
      "\n",
      "\u001b[1m 5000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:40\u001b[0m 43ms/step - accuracy: 0.5353 - loss: 1.4994\n",
      "Final do lote 5000, Loss do lote: 1.4338515996932983\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em minha olha ela para apapel são?\n",
      "“és honra, o qu\n",
      "\n",
      "\u001b[1m 5999/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:01\u001b[0m 43ms/step - accuracy: 0.5385 - loss: 1.4875\n",
      "Final do lote 6000, Loss do lote: 1.421118974685669\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a pálpito do melhor e daquele santuárioso. galguta\n",
      "\n",
      "\u001b[1m 7000/31246\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:18\u001b[0m 43ms/step - accuracy: 0.5414 - loss: 1.4772\n",
      "Final do lote 7000, Loss do lote: 1.4096812009811401\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava entre literária. no povo virá de\n",
      "amor\n",
      "eu um montan\n",
      "\n",
      "\u001b[1m 7999/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:37\u001b[0m 43ms/step - accuracy: 0.5439 - loss: 1.4681\n",
      "Final do lote 8000, Loss do lote: 1.4003394842147827\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ainda; mas\n",
      "espinhosa mais outro que lhe deste dia \n",
      "\n",
      "\u001b[1m 9000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:54\u001b[0m 43ms/step - accuracy: 0.5462 - loss: 1.4602\n",
      "Final do lote 9000, Loss do lote: 1.3931241035461426\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o fim que um bracidade. a sra. d. tertujo é murtia\n",
      "\n",
      "\u001b[1m10000/31246\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:11\u001b[0m 43ms/step - accuracy: 0.5483 - loss: 1.4531\n",
      "Final do lote 10000, Loss do lote: 1.3856478929519653\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava reconhecido; fazer-te uma popidou, mas dever de am\n",
      "\n",
      "\u001b[1m10999/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m14:29\u001b[0m 43ms/step - accuracy: 0.5502 - loss: 1.4467\n",
      "Final do lote 11000, Loss do lote: 1.3792078495025635\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava e o século.\n",
      "\n",
      "rua de execuçado o zoupusto (é porque\n",
      "\n",
      "\u001b[1m11999/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m13:48\u001b[0m 43ms/step - accuracy: 0.5520 - loss: 1.4408\n",
      "Final do lote 12000, Loss do lote: 1.3723870515823364\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava elas.\n",
      "\n",
      "excefipe se aí isso — é tem feliz cois cons\n",
      "\n",
      "\u001b[1m13000/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13:05\u001b[0m 43ms/step - accuracy: 0.5536 - loss: 1.4353\n",
      "Final do lote 13000, Loss do lote: 1.3661692142486572\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a\n",
      "tende ao\n",
      "próprio grande menos enverços do dos da\n",
      "\n",
      "\u001b[1m14000/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12:22\u001b[0m 43ms/step - accuracy: 0.5551 - loss: 1.4301\n",
      "Final do lote 14000, Loss do lote: 1.3617876768112183\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de me poderia; tem nada mais induzem que entusiaês\n",
      "\n",
      "\u001b[1m14999/31246\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11:40\u001b[0m 43ms/step - accuracy: 0.5565 - loss: 1.4255\n",
      "Final do lote 15000, Loss do lote: 1.3595305681228638\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o daduzos; limbeiro narração apaixova, ou não temo\n",
      "\n",
      "\u001b[1m16000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10:57\u001b[0m 43ms/step - accuracy: 0.5578 - loss: 1.4213\n",
      "Final do lote 16000, Loss do lote: 1.3559247255325317\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a comédia — em os marcos, intimidaveram elegândo a\n",
      "\n",
      "\u001b[1m17000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10:14\u001b[0m 43ms/step - accuracy: 0.5590 - loss: 1.4174\n",
      "Final do lote 17000, Loss do lote: 1.3536086082458496\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava fácil a quem\n",
      "sempre a saírem amagerada por que lhe\n",
      "\n",
      "\u001b[1m17999/31246\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9:30\u001b[0m 43ms/step - accuracy: 0.5601 - loss: 1.4138\n",
      "Final do lote 18000, Loss do lote: 1.3523727655410767\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava espírito, tomaga minha ligado o artístico aceste a\n",
      "\n",
      "\u001b[1m18999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8:47\u001b[0m 43ms/step - accuracy: 0.5611 - loss: 1.4105\n",
      "Final do lote 19000, Loss do lote: 1.3509528636932373\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava vai nisto, não\n",
      "sistempores. cresclimento para cond\n",
      "\n",
      "\u001b[1m19999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8:04\u001b[0m 43ms/step - accuracy: 0.5620 - loss: 1.4075\n",
      "Final do lote 20000, Loss do lote: 1.3500474691390991\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em sentir feita dar.\n",
      "\n",
      "como sem direito.\n",
      "\n",
      "\n",
      "o sr. me\n",
      "\n",
      "\u001b[1m21000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7:20\u001b[0m 43ms/step - accuracy: 0.5629 - loss: 1.4048\n",
      "Final do lote 21000, Loss do lote: 1.349905014038086\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava rio\n",
      "inteligência em cercariam intelectual com\n",
      "está\n",
      "\n",
      "\u001b[1m21999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6:38\u001b[0m 43ms/step - accuracy: 0.5636 - loss: 1.4023\n",
      "Final do lote 22000, Loss do lote: 1.3508877754211426\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava me dizer! ruizér-te que trazer disso: – recebenda.\n",
      "\n",
      "\u001b[1m22999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m5:54\u001b[0m 43ms/step - accuracy: 0.5643 - loss: 1.4001\n",
      "Final do lote 23000, Loss do lote: 1.3523342609405518\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava sejam a oração de sua maneira muitos outroras! eu \n",
      "\n",
      "\u001b[1m24000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5:12\u001b[0m 43ms/step - accuracy: 0.5650 - loss: 1.3981\n",
      "Final do lote 24000, Loss do lote: 1.3532756567001343\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a que não tem resto dos passam quem\n",
      "*\n",
      "\n",
      "*\n",
      "\n",
      "ver, ele\n",
      "\n",
      "\u001b[1m24999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4:29\u001b[0m 43ms/step - accuracy: 0.5655 - loss: 1.3963\n",
      "Final do lote 25000, Loss do lote: 1.353964924812317\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ao\n",
      "depois de novo desperificulos. as conversões, o\n",
      "\n",
      "\u001b[1m26000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3:46\u001b[0m 43ms/step - accuracy: 0.5660 - loss: 1.3947\n",
      "Final do lote 26000, Loss do lote: 1.3541080951690674\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a escrever a coisa fialis e que tem se artísticoss\n",
      "\n",
      "\u001b[1m27000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:02\u001b[0m 43ms/step - accuracy: 0.5665 - loss: 1.3932\n",
      "Final do lote 27000, Loss do lote: 1.353915810585022\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava amaterar o filho desombos de uma estrépito.\n",
      "\n",
      "pedro\n",
      "\n",
      "\u001b[1m27999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2:19\u001b[0m 43ms/step - accuracy: 0.5670 - loss: 1.3918\n",
      "Final do lote 28000, Loss do lote: 1.3535057306289673\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ao jupida, de julgos da literatura é uma\n",
      "exibição \n",
      "\n",
      "\u001b[1m29000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:36\u001b[0m 43ms/step - accuracy: 0.5674 - loss: 1.3905\n",
      "Final do lote 29000, Loss do lote: 1.3527061939239502\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a geração ardentes de sergue gênero da\n",
      "estréia se \n",
      "\n",
      "\u001b[1m29999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - accuracy: 0.5678 - loss: 1.3892\n",
      "Final do lote 30000, Loss do lote: 1.35132896900177\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava estabícia o campo os anos e cidade estes avultadas\n",
      "\n",
      "\u001b[1m31000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.5682 - loss: 1.3879\n",
      "Final do lote 31000, Loss do lote: 1.3497487306594849\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava hoje que presente acordo por uma mão, mas à palavr\n",
      "\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5683 - loss: 1.3876Final da época 5, Loss: 1.3493266105651855, Acc: 0.5804775357246399\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1437s\u001b[0m 46ms/step - accuracy: 0.5683 - loss: 1.3876 - val_accuracy: 0.5245 - val_loss: 1.6034\n",
      "Epoch 7/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 1.9971058368682861\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que\n",
      "elvira em outro próxios mesquitos de afrifeian\n",
      "\n",
      "\u001b[1m 1000/31246\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46:27\u001b[0m 92ms/step - accuracy: 0.5069 - loss: 1.6138\n",
      "Final do lote 1000, Loss do lote: 1.5266695022583008\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava antes projeto\n",
      "tu tristes;\n",
      "e não eu confessa aguaçã\n",
      "\n",
      "\u001b[1m 2000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46:45\u001b[0m 96ms/step - accuracy: 0.5208 - loss: 1.5573\n",
      "Final do lote 2000, Loss do lote: 1.4829421043395996\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava impuestou\n",
      " pequenino da infantio moviais\n",
      "de dareis\n",
      "\n",
      "\u001b[1m 3000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46:00\u001b[0m 98ms/step - accuracy: 0.5279 - loss: 1.5284\n",
      "Final do lote 3000, Loss do lote: 1.459435224533081\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava essa!\n",
      "isso não refletiste mundo adtulouro,\n",
      "“como a\n",
      "\n",
      "\u001b[1m 4000/31246\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44:36\u001b[0m 98ms/step - accuracy: 0.5329 - loss: 1.5090\n",
      "Final do lote 4000, Loss do lote: 1.442395567893982\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a\n",
      "mão dele? antes que nos fadia,\n",
      "payências fobeste\n",
      "\n",
      "\u001b[1m 5000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43:12\u001b[0m 99ms/step - accuracy: 0.5368 - loss: 1.4942\n",
      "Final do lote 5000, Loss do lote: 1.4287840127944946\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava um pouco dramáticas desejos de cheias\n",
      "culto nem\n",
      "um\n",
      "\n",
      "\u001b[1m 6000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41:46\u001b[0m 99ms/step - accuracy: 0.5401 - loss: 1.4822\n",
      "Final do lote 6000, Loss do lote: 1.4155149459838867\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a ação. não entra furtaria em marinheste muda, emp\n",
      "\n",
      "\u001b[1m 7000/31246\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40:11\u001b[0m 99ms/step - accuracy: 0.5430 - loss: 1.4718\n",
      "Final do lote 7000, Loss do lote: 1.4038562774658203\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava entre está o ginásio. fora do meu maria, por estas\n",
      "\n",
      "\u001b[1m 8000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38:41\u001b[0m 100ms/step - accuracy: 0.5456 - loss: 1.4627\n",
      "Final do lote 8000, Loss do lote: 1.3946815729141235\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava disposição. a mim, mas, se me fazendo de recitar e\n",
      "\n",
      "\u001b[1m 9000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36:53\u001b[0m 100ms/step - accuracy: 0.5479 - loss: 1.4548\n",
      "Final do lote 9000, Loss do lote: 1.3873783349990845\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava não se\n",
      "dura;\n",
      "um drama. é como aconcer o belo dó al\n",
      "\n",
      "\u001b[1m 9999/31246\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34:48\u001b[0m 98ms/step - accuracy: 0.5499 - loss: 1.4477\n",
      "Final do lote 10000, Loss do lote: 1.3800348043441772\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o teatro e como eis através. a avelturado público \n",
      "\n",
      "\u001b[1m10999/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m31:31\u001b[0m 93ms/step - accuracy: 0.5518 - loss: 1.4412\n",
      "Final do lote 11000, Loss do lote: 1.3736766576766968\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava surgentes fundas ao teatro de a literatura, em que\n",
      "\n",
      "\u001b[1m12000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m28:44\u001b[0m 90ms/step - accuracy: 0.5536 - loss: 1.4353\n",
      "Final do lote 12000, Loss do lote: 1.3669157028198242\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava aguarei a diante,\n",
      "desenvolver\n",
      "indiscre. consolava \n",
      "\n",
      "\u001b[1m12999/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m26:15\u001b[0m 86ms/step - accuracy: 0.5552 - loss: 1.4298\n",
      "Final do lote 13000, Loss do lote: 1.3604109287261963\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava irealidade de\n",
      "enquanto senteparatura dos cordas es\n",
      "\n",
      "\u001b[1m14000/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m24:36\u001b[0m 86ms/step - accuracy: 0.5567 - loss: 1.4247\n",
      "Final do lote 14000, Loss do lote: 1.3580727577209473\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de\n",
      "apoia: resezos\n",
      "corres\n",
      "e dramática se ser depois\n",
      "\n",
      "\u001b[1m15000/31246\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23:18\u001b[0m 86ms/step - accuracy: 0.5581 - loss: 1.4203\n",
      "Final do lote 15000, Loss do lote: 1.35801362991333\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o brasia — podia elisa a esperar os seus de escrav\n",
      "\n",
      "\u001b[1m15999/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21:18\u001b[0m 84ms/step - accuracy: 0.5593 - loss: 1.4163\n",
      "Final do lote 16000, Loss do lote: 1.3546291589736938\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava só propor-me l’amont a sua esposa.\n",
      "\n",
      "clara\n",
      "\n",
      "acho de\n",
      "\n",
      "\u001b[1m16999/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19:26\u001b[0m 82ms/step - accuracy: 0.5604 - loss: 1.4126\n",
      "Final do lote 17000, Loss do lote: 1.3524569272994995\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a sua empresência, no bater daquele espírito cheia\n",
      "\n",
      "\u001b[1m18000/31246\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17:39\u001b[0m 80ms/step - accuracy: 0.5614 - loss: 1.4092\n",
      "Final do lote 18000, Loss do lote: 1.3511301279067993\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava crito de uma direito, certeza, são os mundos do qu\n",
      "\n",
      "\u001b[1m19000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16:01\u001b[0m 79ms/step - accuracy: 0.5624 - loss: 1.4061\n",
      "Final do lote 19000, Loss do lote: 1.3498053550720215\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava aos clarinentes\n",
      "algumas coisas;\n",
      "em que\n",
      "vamos nos\n",
      "e\n",
      "\n",
      "\u001b[1m20000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14:27\u001b[0m 77ms/step - accuracy: 0.5633 - loss: 1.4033\n",
      "Final do lote 20000, Loss do lote: 1.3488954305648804\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o caber metade debaixo dos voltarás. \n",
      "tendo de ser\n",
      "\n",
      "\u001b[1m21000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12:57\u001b[0m 76ms/step - accuracy: 0.5641 - loss: 1.4007\n",
      "Final do lote 21000, Loss do lote: 1.3486045598983765\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava assim, não;\n",
      "exquecto do abraça de um príncipe felh\n",
      "\n",
      "\u001b[1m21999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11:31\u001b[0m 75ms/step - accuracy: 0.5648 - loss: 1.3983\n",
      "Final do lote 22000, Loss do lote: 1.3496192693710327\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava eles\n",
      "questões fazer uniu os podias de idia do que\n",
      "\n",
      "\n",
      "\u001b[1m22999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10:07\u001b[0m 74ms/step - accuracy: 0.5654 - loss: 1.3962\n",
      "Final do lote 23000, Loss do lote: 1.3508566617965698\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ao homens verdes\n",
      "as indiferena\n",
      "começou.\n",
      "\n",
      "voltetim;\n",
      "\n",
      "\u001b[1m23999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8:46\u001b[0m 73ms/step - accuracy: 0.5660 - loss: 1.3944\n",
      "Final do lote 24000, Loss do lote: 1.351681113243103\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava aos entendições, grita acredite as ressuram-se faz\n",
      "\n",
      "\u001b[1m25000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7:28\u001b[0m 72ms/step - accuracy: 0.5666 - loss: 1.3927\n",
      "Final do lote 25000, Loss do lote: 1.3523566722869873\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que a peça por mar destino que\n",
      "não e importante, u\n",
      "\n",
      "\u001b[1m26000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6:12\u001b[0m 71ms/step - accuracy: 0.5670 - loss: 1.3911\n",
      "Final do lote 26000, Loss do lote: 1.3523629903793335\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava 5.º ato mesmo da novidade.\n",
      "quem — gozes.\n",
      "\n",
      "o suplit\n",
      "\n",
      "\u001b[1m27000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4:57\u001b[0m 70ms/step - accuracy: 0.5675 - loss: 1.3897\n",
      "Final do lote 27000, Loss do lote: 1.3520584106445312\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava eu pensude, ou que é inspira\n",
      "crer que ontem, em re\n",
      "\n",
      "\u001b[1m28000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:45\u001b[0m 70ms/step - accuracy: 0.5679 - loss: 1.3883\n",
      "Final do lote 28000, Loss do lote: 1.3516077995300293\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava avariada; esta querido esta sido, falar dito,\n",
      "rari\n",
      "\n",
      "\u001b[1m29000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2:38\u001b[0m 70ms/step - accuracy: 0.5683 - loss: 1.3871\n",
      "Final do lote 29000, Loss do lote: 1.350694179534912\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava nos britos? é está tomar-se desde equinos pela pri\n",
      "\n",
      "\u001b[1m30000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:27\u001b[0m 71ms/step - accuracy: 0.5687 - loss: 1.3858\n",
      "Final do lote 30000, Loss do lote: 1.3492735624313354\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava todas as mais a sentia fará pública. dizer-lheaça-\n",
      "\n",
      "\u001b[1m31000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m17s\u001b[0m 71ms/step - accuracy: 0.5691 - loss: 1.3846\n",
      "Final do lote 31000, Loss do lote: 1.3475741147994995\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava as parecer-se tão presenço, querem até em cena\n",
      "8..\n",
      "\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5692 - loss: 1.3843Final da época 6, Loss: 1.347148060798645, Acc: 0.5808775424957275\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2328s\u001b[0m 73ms/step - accuracy: 0.5692 - loss: 1.3843 - val_accuracy: 0.5233 - val_loss: 1.6005\n",
      "Epoch 8/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 1.9303314685821533\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava era, dias inconte:\n",
      "\n",
      "o reche dada dar; mas\n",
      "aprecian\n",
      "\n",
      "\u001b[1m 1000/31246\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:47\u001b[0m 91ms/step - accuracy: 0.5081 - loss: 1.6076\n",
      "Final do lote 1000, Loss do lote: 1.521738052368164\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava arredo a\n",
      "cinsídi, ou o junhe da malidade,\n",
      "outro co\n",
      "\n",
      "\u001b[1m 2000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:43\u001b[0m 94ms/step - accuracy: 0.5217 - loss: 1.5519\n",
      "Final do lote 2000, Loss do lote: 1.4780293703079224\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava rasgado\n",
      "além com os pés\n",
      "achaqueis, cuja novidades \n",
      "\n",
      "\u001b[1m 3000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44:44\u001b[0m 95ms/step - accuracy: 0.5288 - loss: 1.5234\n",
      "Final do lote 3000, Loss do lote: 1.4554980993270874\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava aqui a história que\n",
      "juntam adorna um sois.\n",
      "não me \n",
      "\n",
      "\u001b[1m 4000/31246\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43:17\u001b[0m 95ms/step - accuracy: 0.5337 - loss: 1.5043\n",
      "Final do lote 4000, Loss do lote: 1.438976764678955\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava um lar;\n",
      "recebida último parasita, que eira, sob a\n",
      "\n",
      "\n",
      "\u001b[1m 5000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41:44\u001b[0m 95ms/step - accuracy: 0.5375 - loss: 1.4898\n",
      "Final do lote 5000, Loss do lote: 1.4254181385040283\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava num quatro\n",
      "que é do desejo... inda ao viedo\n",
      "das pi\n",
      "\n",
      "\u001b[1m 6000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40:13\u001b[0m 96ms/step - accuracy: 0.5407 - loss: 1.4780\n",
      "Final do lote 6000, Loss do lote: 1.4121249914169312\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de atravesso costume de mais\n",
      "quando entre gentes t\n",
      "\n",
      "\u001b[1m 7000/31246\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38:43\u001b[0m 96ms/step - accuracy: 0.5436 - loss: 1.4677\n",
      "Final do lote 7000, Loss do lote: 1.4008179903030396\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em condessa vão casamento\n",
      "extens. neste drama no\n",
      "m\n",
      "\n",
      "\u001b[1m 8000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37:11\u001b[0m 96ms/step - accuracy: 0.5461 - loss: 1.4587\n",
      "Final do lote 8000, Loss do lote: 1.3915635347366333\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a platéia uma réficinsa. tinha cabo dramático legi\n",
      "\n",
      "\u001b[1m 9000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35:41\u001b[0m 96ms/step - accuracy: 0.5484 - loss: 1.4509\n",
      "Final do lote 9000, Loss do lote: 1.3843657970428467\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a sra. meneu, e sublrição de painista fechado\n",
      "em t\n",
      "\n",
      "\u001b[1m10000/31246\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34:04\u001b[0m 96ms/step - accuracy: 0.5504 - loss: 1.4439\n",
      "Final do lote 10000, Loss do lote: 1.3769901990890503\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que\n",
      "dedicação do si uma poetalidade. a perfeitam o\n",
      "\n",
      "\u001b[1m11000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m32:30\u001b[0m 96ms/step - accuracy: 0.5523 - loss: 1.4375\n",
      "Final do lote 11000, Loss do lote: 1.3706443309783936\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que tem asas deste opulado o quaime\n",
      "uma noite,\n",
      "que\n",
      "\n",
      "\u001b[1m12000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m30:54\u001b[0m 96ms/step - accuracy: 0.5540 - loss: 1.4316\n",
      "Final do lote 12000, Loss do lote: 1.3638722896575928\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava autor d'o hesriu, chamoutosa, não me desempenhou c\n",
      "\n",
      "\u001b[1m12999/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29:13\u001b[0m 96ms/step - accuracy: 0.5557 - loss: 1.4262\n",
      "Final do lote 13000, Loss do lote: 1.3573611974716187\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava destinado de\n",
      "observação estava a prova.\n",
      " toma-lo a\n",
      "\n",
      "\u001b[1m14000/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m27:32\u001b[0m 96ms/step - accuracy: 0.5572 - loss: 1.4211\n",
      "Final do lote 14000, Loss do lote: 1.3532243967056274\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em portugadiole arranveve de expressão burlesco, a\n",
      "\n",
      "\u001b[1m15000/31246\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m25:57\u001b[0m 96ms/step - accuracy: 0.5585 - loss: 1.4165\n",
      "Final do lote 15000, Loss do lote: 1.3510031700134277\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava sem parte do certew édida o cupilhar.\n",
      "\n",
      "feliz censo\n",
      "\n",
      "\u001b[1m16000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m24:23\u001b[0m 96ms/step - accuracy: 0.5598 - loss: 1.4123\n",
      "Final do lote 16000, Loss do lote: 1.3473812341690063\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em v. exa. quanto descrevícel, os versos\n",
      "que um de\n",
      "\n",
      "\u001b[1m17000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m22:47\u001b[0m 96ms/step - accuracy: 0.5610 - loss: 1.4084\n",
      "Final do lote 17000, Loss do lote: 1.345134973526001\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava os exteriosa, mem interromona\n",
      "criança de avecar to\n",
      "\n",
      "\u001b[1m18000/31246\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21:10\u001b[0m 96ms/step - accuracy: 0.5621 - loss: 1.4048\n",
      "Final do lote 18000, Loss do lote: 1.3438843488693237\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava mais conversar de intenção,\n",
      "o meio da cena do peit\n",
      "\n",
      "\u001b[1m19000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m19:35\u001b[0m 96ms/step - accuracy: 0.5631 - loss: 1.4016\n",
      "Final do lote 19000, Loss do lote: 1.342629075050354\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em.\n",
      "\n",
      "pedro alves\n",
      "\n",
      "vamos novescura com que escola-s\n",
      "\n",
      "\u001b[1m20000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m17:55\u001b[0m 96ms/step - accuracy: 0.5640 - loss: 1.3986\n",
      "Final do lote 20000, Loss do lote: 1.3416345119476318\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava menina apenas um drama menese, a honra,\n",
      "e graves d\n",
      "\n",
      "\u001b[1m21000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m16:20\u001b[0m 96ms/step - accuracy: 0.5648 - loss: 1.3959\n",
      "Final do lote 21000, Loss do lote: 1.341520071029663\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava deste favores reputações indiscrescridas de tol co\n",
      "\n",
      "\u001b[1m22000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m14:45\u001b[0m 96ms/step - accuracy: 0.5656 - loss: 1.3934\n",
      "Final do lote 22000, Loss do lote: 1.3423888683319092\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em misti, da expede dençair os\n",
      "lugar\n",
      "molières.\n",
      "\n",
      "pa\n",
      "\n",
      "\u001b[1m23000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13:10\u001b[0m 96ms/step - accuracy: 0.5663 - loss: 1.3913\n",
      "Final do lote 23000, Loss do lote: 1.343753457069397\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava para de maior dos pontas em mão\n",
      "uma moxáquana. nem\n",
      "\n",
      "\u001b[1m23999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m11:30\u001b[0m 95ms/step - accuracy: 0.5669 - loss: 1.3893\n",
      "Final do lote 24000, Loss do lote: 1.3447085618972778\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava consista.\n",
      "\n",
      "estido enfim — a companhia. reprevo a v\n",
      "\n",
      "\u001b[1m25000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m9:45\u001b[0m 94ms/step - accuracy: 0.5674 - loss: 1.3875\n",
      "Final do lote 25000, Loss do lote: 1.3455921411514282\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a\n",
      "quanta andam com o meba inspirada.\n",
      "\n",
      "o inferiado \n",
      "\n",
      "\u001b[1m26000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8:25\u001b[0m 96ms/step - accuracy: 0.5680 - loss: 1.3859\n",
      "Final do lote 26000, Loss do lote: 1.3457951545715332\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava por justificada algumas musindos\n",
      "de carrapato, mas\n",
      "\n",
      "\u001b[1m27000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6:49\u001b[0m 96ms/step - accuracy: 0.5684 - loss: 1.3844\n",
      "Final do lote 27000, Loss do lote: 1.345609188079834\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a saudo que fazem caracterago, no primeiro ato dev\n",
      "\n",
      "\u001b[1m28000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5:12\u001b[0m 96ms/step - accuracy: 0.5689 - loss: 1.3830\n",
      "Final do lote 28000, Loss do lote: 1.345213770866394\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a superiana, que é sem destes\n",
      "semivições mosbres, \n",
      "\n",
      "\u001b[1m29000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3:36\u001b[0m 96ms/step - accuracy: 0.5693 - loss: 1.3817\n",
      "Final do lote 29000, Loss do lote: 1.3446567058563232\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ; de apórlico,\n",
      "haver em quadro, destes quadros pen\n",
      "\n",
      "\u001b[1m30000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2:00\u001b[0m 97ms/step - accuracy: 0.5697 - loss: 1.3805\n",
      "Final do lote 30000, Loss do lote: 1.3441303968429565\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a cidade?”\n",
      "desparcemos.\n",
      "o drama leva a obra é tudo\n",
      "\n",
      "\u001b[1m31000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m23s\u001b[0m 97ms/step - accuracy: 0.5701 - loss: 1.3794\n",
      "Final do lote 31000, Loss do lote: 1.345658779144287\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que vez um país penetraram queira, ou viú expiraçã\n",
      "\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5702 - loss: 1.3791Final da época 7, Loss: 1.3454948663711548, Acc: 0.5809599161148071\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3108s\u001b[0m 99ms/step - accuracy: 0.5702 - loss: 1.3791 - val_accuracy: 0.5227 - val_loss: 1.6000\n",
      "Epoch 9/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 2.01880145072937\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava elas pessoas, comiga e os governos já me páginas d\n",
      "\n",
      "\u001b[1m 1000/31246\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47:07\u001b[0m 93ms/step - accuracy: 0.4998 - loss: 1.6321\n",
      "Final do lote 1000, Loss do lote: 1.551587700843811\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em fundo.\n",
      "então, tanto antigo tempo,\n",
      "palmas do dou\n",
      "\n",
      "\u001b[1m 2000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47:13\u001b[0m 97ms/step - accuracy: 0.5130 - loss: 1.5788\n",
      "Final do lote 2000, Loss do lote: 1.5068950653076172\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava um peraço do condenta!\n",
      "luta vólenso ao um entusias\n",
      "\n",
      "\u001b[1m 3000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:56\u001b[0m 98ms/step - accuracy: 0.5202 - loss: 1.5504\n",
      "Final do lote 3000, Loss do lote: 1.4810782670974731\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava por anuno de méticos —\n",
      "\n",
      "toda a nossa guipansectren\n",
      "\n",
      "\u001b[1m 4000/31246\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44:29\u001b[0m 98ms/step - accuracy: 0.5254 - loss: 1.5305\n",
      "Final do lote 4000, Loss do lote: 1.461578369140625\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ou qualquires\n",
      "corpo na morto que convém é bisço se\n",
      "\n",
      "\u001b[1m 5000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42:54\u001b[0m 98ms/step - accuracy: 0.5296 - loss: 1.5151\n",
      "Final do lote 5000, Loss do lote: 1.4452306032180786\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava intensolince, o fervo e o silve haar. quadro públi\n",
      "\n",
      "\u001b[1m 6000/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41:24\u001b[0m 98ms/step - accuracy: 0.5332 - loss: 1.5021\n",
      "Final do lote 6000, Loss do lote: 1.4299044609069824\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava à nataluidade:\n",
      "encarpinho que é no ti! que goza in\n",
      "\n",
      "\u001b[1m 7000/31246\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37:26\u001b[0m 93ms/step - accuracy: 0.5364 - loss: 1.4909\n",
      "Final do lote 7000, Loss do lote: 1.416459560394287\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava um princípio.\n",
      "\n",
      "verificar jugíss.\n",
      "\n",
      "oras esse saúde \n",
      "\n",
      "\u001b[1m 7999/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33:32\u001b[0m 87ms/step - accuracy: 0.5393 - loss: 1.4808\n",
      "Final do lote 8000, Loss do lote: 1.4053781032562256\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava vale, e passeu estava, caíscioso também diretard..\n",
      "\n",
      "\u001b[1m 9000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30:20\u001b[0m 82ms/step - accuracy: 0.5419 - loss: 1.4720\n",
      "Final do lote 9000, Loss do lote: 1.3965249061584473\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava já escapa susvempeisada de um ano de conto-se o qu\n",
      "\n",
      "\u001b[1m10000/31246\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m27:40\u001b[0m 78ms/step - accuracy: 0.5442 - loss: 1.4640\n",
      "Final do lote 10000, Loss do lote: 1.3880482912063599\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava outro segundo ampla?\n",
      "\n",
      "rosinho\n",
      "\n",
      "pratigo est’alma, n\n",
      "\n",
      "\u001b[1m10999/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m25:19\u001b[0m 75ms/step - accuracy: 0.5464 - loss: 1.4567\n",
      "Final do lote 11000, Loss do lote: 1.380467414855957\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o talento da prostrio.\n",
      "\n",
      "e nascido mais apareceu ne\n",
      "\n",
      "\u001b[1m12000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23:24\u001b[0m 73ms/step - accuracy: 0.5484 - loss: 1.4501\n",
      "Final do lote 12000, Loss do lote: 1.3731200695037842\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava para o assim.\n",
      "\n",
      "sustenciativa!\n",
      "justifica-se os temp\n",
      "\n",
      "\u001b[1m12999/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21:32\u001b[0m 71ms/step - accuracy: 0.5502 - loss: 1.4439\n",
      "Final do lote 13000, Loss do lote: 1.3659168481826782\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de mais ou simples é simpático de relação. porque \n",
      "\n",
      "\u001b[1m13999/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m20:17\u001b[0m 71ms/step - accuracy: 0.5519 - loss: 1.4381\n",
      "Final do lote 14000, Loss do lote: 1.3611254692077637\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava m; não por\n",
      "um anjo e\n",
      "estas ocâmias estão a cena vi\n",
      "\n",
      "\u001b[1m15000/31246\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m18:38\u001b[0m 69ms/step - accuracy: 0.5535 - loss: 1.4329\n",
      "Final do lote 15000, Loss do lote: 1.3580832481384277\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a justo, coereiro desenvolvem com resomo nas preon\n",
      "\n",
      "\u001b[1m15999/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m17:06\u001b[0m 67ms/step - accuracy: 0.5549 - loss: 1.4281\n",
      "Final do lote 16000, Loss do lote: 1.353800892829895\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava na das ações francorolisos.\n",
      "\n",
      "pedro alista-se no me\n",
      "\n",
      "\u001b[1m17000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m15:39\u001b[0m 66ms/step - accuracy: 0.5563 - loss: 1.4236\n",
      "Final do lote 17000, Loss do lote: 1.351049542427063\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava voltar os defrontes espertados,\n",
      "contrairam-se guar\n",
      "\n",
      "\u001b[1m17999/31246\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m14:18\u001b[0m 65ms/step - accuracy: 0.5575 - loss: 1.4195\n",
      "Final do lote 18000, Loss do lote: 1.3492357730865479\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava constitui um já variedade de mesmo volu,\n",
      "de perto \n",
      "\n",
      "\u001b[1m19000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13:00\u001b[0m 64ms/step - accuracy: 0.5587 - loss: 1.4158\n",
      "Final do lote 19000, Loss do lote: 1.3473514318466187\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava à pratar os belos alguns\n",
      "quem tenho em quê?\n",
      "\n",
      "fala \n",
      "\n",
      "\u001b[1m19999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m11:46\u001b[0m 63ms/step - accuracy: 0.5597 - loss: 1.4123\n",
      "Final do lote 20000, Loss do lote: 1.3460062742233276\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava colcerem.\n",
      "\n",
      "luís\n",
      "\n",
      "nem razão; as reconheceu deveremo\n",
      "\n",
      "\u001b[1m21000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m10:35\u001b[0m 62ms/step - accuracy: 0.5607 - loss: 1.4091\n",
      "Final do lote 21000, Loss do lote: 1.3455389738082886\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava movimentos a fonte dos naciaram. entende valham, n\n",
      "\n",
      "\u001b[1m22000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m9:26\u001b[0m 61ms/step - accuracy: 0.5616 - loss: 1.4063\n",
      "Final do lote 22000, Loss do lote: 1.3460144996643066\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava por uma parte aos operários\n",
      "mostrais — excelência \n",
      "\n",
      "\u001b[1m23000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m8:19\u001b[0m 61ms/step - accuracy: 0.5624 - loss: 1.4037\n",
      "Final do lote 23000, Loss do lote: 1.3470218181610107\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava liuto, escolheu o\n",
      "sabem quis agrez devitar.\n",
      "\n",
      "pedro\n",
      "\n",
      "\u001b[1m23999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7:14\u001b[0m 60ms/step - accuracy: 0.5631 - loss: 1.4013\n",
      "Final do lote 24000, Loss do lote: 1.3476134538650513\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a duram nela.\n",
      "\n",
      "de causa deixar. conjunço des\n",
      "mais \n",
      "\n",
      "\u001b[1m24999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6:10\u001b[0m 59ms/step - accuracy: 0.5638 - loss: 1.3992\n",
      "Final do lote 25000, Loss do lote: 1.3481295108795166\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava progresso? talvez do melhoramento\n",
      "muito prata, fév\n",
      "\n",
      "\u001b[1m25999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5:08\u001b[0m 59ms/step - accuracy: 0.5644 - loss: 1.3972\n",
      "Final do lote 26000, Loss do lote: 1.3480465412139893\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a das ordens vei tratei nabutar o último passeio d\n",
      "\n",
      "\u001b[1m27000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4:07\u001b[0m 58ms/step - accuracy: 0.5650 - loss: 1.3954\n",
      "Final do lote 27000, Loss do lote: 1.34766685962677\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava na vício drama dos carroçosos, porque ficam\n",
      "ainda \n",
      "\n",
      "\u001b[1m28000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:07\u001b[0m 58ms/step - accuracy: 0.5655 - loss: 1.3937\n",
      "Final do lote 28000, Loss do lote: 1.3470979928970337\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava para também da restada a\n",
      "prédique dedica irá.,\n",
      "nem\n",
      "\n",
      "\u001b[1m29000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2:08\u001b[0m 57ms/step - accuracy: 0.5661 - loss: 1.3921\n",
      "Final do lote 29000, Loss do lote: 1.3461861610412598\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava assinaturas e dodinho quando delicadas as\n",
      "trocondo\n",
      "\n",
      "\u001b[1m29999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1:10\u001b[0m 57ms/step - accuracy: 0.5665 - loss: 1.3905\n",
      "Final do lote 30000, Loss do lote: 1.3447635173797607\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava medrofe, e tornando; encadem\n",
      "à cidade é o como de \n",
      "\n",
      "\u001b[1m31000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - accuracy: 0.5670 - loss: 1.3890\n",
      "Final do lote 31000, Loss do lote: 1.3430734872817993\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava tangada em decrados.\n",
      "dá molécio compla, à\n",
      "ministér\n",
      "\n",
      "\u001b[1m31245/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5671 - loss: 1.3886Final da época 8, Loss: 1.342628836631775, Acc: 0.5815444588661194\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1812s\u001b[0m 57ms/step - accuracy: 0.5671 - loss: 1.3886 - val_accuracy: 0.5258 - val_loss: 1.6023\n",
      "Epoch 10/10\n",
      "\n",
      "Final do lote 0, Loss do lote: 1.899339199066162\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava uma lagar-se havendo a retratar a dúvida abrir na \n",
      "\n",
      "\u001b[1m  999/31246\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21:22\u001b[0m 42ms/step - accuracy: 0.5075 - loss: 1.6111\n",
      "Final do lote 1000, Loss do lote: 1.5231115818023682\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava com cobela.\n",
      "é sucedem do ar?\n",
      "poeta de douton da tr\n",
      "\n",
      "\u001b[1m 2000/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21:08\u001b[0m 43ms/step - accuracy: 0.5209 - loss: 1.5544\n",
      "Final do lote 2000, Loss do lote: 1.4802592992782593\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava minh’amistalidade\n",
      "siltante descrição, — e proseiro\n",
      "\n",
      "\u001b[1m 2999/31246\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:43\u001b[0m 44ms/step - accuracy: 0.5278 - loss: 1.5255\n",
      "Final do lote 3000, Loss do lote: 1.4559756517410278\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ferres, manta, ainda a queda memória, lágrima fron\n",
      "\n",
      "\u001b[1m 4000/31246\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:06\u001b[0m 44ms/step - accuracy: 0.5316 - loss: 1.5105\n",
      "Final do lote 4000, Loss do lote: 1.4935047626495361\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava manguiça nesse primeira das votas e amar.\n",
      "seu nova\n",
      "\n",
      "\u001b[1m 4999/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:23\u001b[0m 44ms/step - accuracy: 0.5321 - loss: 1.5088\n",
      "Final do lote 5000, Loss do lote: 1.5053874254226685\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava seria nas decipenas, da porta\n",
      "às citéres — há e en\n",
      "\n",
      "\u001b[1m 5999/31246\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:42\u001b[0m 44ms/step - accuracy: 0.5324 - loss: 1.5079\n",
      "Final do lote 6000, Loss do lote: 1.4998266696929932\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava doperantório.\n",
      "\n",
      "o público locance moderno apenas\n",
      "a \n",
      "\n",
      "\u001b[1m 6999/31246\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:57\u001b[0m 44ms/step - accuracy: 0.5329 - loss: 1.5061\n",
      "Final do lote 7000, Loss do lote: 1.4896798133850098\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava então pressa\n",
      "caro.\n",
      "\n",
      "é uma pasquer?\n",
      "\n",
      "não é o encont\n",
      "\n",
      "\u001b[1m 8000/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:15\u001b[0m 45ms/step - accuracy: 0.5338 - loss: 1.5033\n",
      "Final do lote 8000, Loss do lote: 1.4792965650558472\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava por uma pública, mas, guiar de sufabulentoso que a\n",
      "\n",
      "\u001b[1m 8999/31246\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:32\u001b[0m 45ms/step - accuracy: 0.5348 - loss: 1.5002\n",
      "Final do lote 9000, Loss do lote: 1.4696319103240967\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava uma notaciais, um cemitivo a\n",
      "leva. é os\n",
      "talentos, \n",
      "\n",
      "\u001b[1m10000/31246\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:49\u001b[0m 45ms/step - accuracy: 0.5360 - loss: 1.4966\n",
      "Final do lote 10000, Loss do lote: 1.4594058990478516\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava por uma\n",
      "prátis e o diano do\n",
      "modo. obstáculos, rari\n",
      "\n",
      "\u001b[1m11000/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15:06\u001b[0m 45ms/step - accuracy: 0.5372 - loss: 1.4928\n",
      "Final do lote 11000, Loss do lote: 1.4497286081314087\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava recompendial.\n",
      "\n",
      "o jovem de jorge.\n",
      "\n",
      "é um dia monto a\n",
      "\n",
      "\u001b[1m11999/31246\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m14:22\u001b[0m 45ms/step - accuracy: 0.5384 - loss: 1.4888\n",
      "Final do lote 12000, Loss do lote: 1.4394233226776123\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o dupla éditar-me que o passo que se reda. mas sen\n",
      "\n",
      "\u001b[1m13000/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13:38\u001b[0m 45ms/step - accuracy: 0.5397 - loss: 1.4846\n",
      "Final do lote 13000, Loss do lote: 1.4293197393417358\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava as aspirados que muito menos\n",
      "o causo do seu canção\n",
      "\n",
      "\u001b[1m13999/31246\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12:54\u001b[0m 45ms/step - accuracy: 0.5410 - loss: 1.4803\n",
      "Final do lote 14000, Loss do lote: 1.4214179515838623\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava templo deixarecem. o sardou à composição em viagad\n",
      "\n",
      "\u001b[1m15000/31246\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12:09\u001b[0m 45ms/step - accuracy: 0.5423 - loss: 1.4762\n",
      "Final do lote 15000, Loss do lote: 1.4156299829483032\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que alflir com os seus estregrias cios: então apes\n",
      "\n",
      "\u001b[1m15999/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11:24\u001b[0m 45ms/step - accuracy: 0.5435 - loss: 1.4722\n",
      "Final do lote 16000, Loss do lote: 1.4087517261505127\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava que no traçaria vamos no caso entre representar as\n",
      "\n",
      "\u001b[1m17000/31246\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10:39\u001b[0m 45ms/step - accuracy: 0.5447 - loss: 1.4683\n",
      "Final do lote 17000, Loss do lote: 1.4032477140426636\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ser si, porquanto do autor? não hoonas da tocabalh\n",
      "\n",
      "\u001b[1m18000/31246\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9:56\u001b[0m 45ms/step - accuracy: 0.5458 - loss: 1.4646\n",
      "Final do lote 18000, Loss do lote: 1.398945689201355\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava o primeiro ator e de kai\n",
      "apenas dos artistas, esta\n",
      "\n",
      "\u001b[1m18999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9:10\u001b[0m 45ms/step - accuracy: 0.5469 - loss: 1.4610\n",
      "Final do lote 19000, Loss do lote: 1.394761562347412\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava afeito da\n",
      "adalidade.\n",
      "\n",
      " ensineão foi é que o poeta \n",
      "\n",
      "\u001b[1m20000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8:26\u001b[0m 45ms/step - accuracy: 0.5479 - loss: 1.4576\n",
      "Final do lote 20000, Loss do lote: 1.3913081884384155\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava antes\n",
      "lesse ou forte. tudo então na breve de longe\n",
      "\n",
      "\u001b[1m21000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7:41\u001b[0m 45ms/step - accuracy: 0.5489 - loss: 1.4544\n",
      "Final do lote 21000, Loss do lote: 1.38877272605896\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de extréfida\n",
      "idjalhas de tal, tivro, que alterra n\n",
      "\n",
      "\u001b[1m22000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6:56\u001b[0m 45ms/step - accuracy: 0.5498 - loss: 1.4514\n",
      "Final do lote 22000, Loss do lote: 1.3874702453613281\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava supremos, como bem foi\n",
      "o diálogo quem tem\n",
      "josé que\n",
      "\n",
      "\u001b[1m22999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6:11\u001b[0m 45ms/step - accuracy: 0.5507 - loss: 1.4486\n",
      "Final do lote 23000, Loss do lote: 1.386739730834961\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava nem\n",
      "dar ao mais ou nesta\n",
      "v. excia, atencidade da p\n",
      "\n",
      "\u001b[1m23999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5:26\u001b[0m 45ms/step - accuracy: 0.5515 - loss: 1.4460\n",
      "Final do lote 24000, Loss do lote: 1.38559889793396\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava horas de pre ferro com um pouco do tempestada, e c\n",
      "\n",
      "\u001b[1m25000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4:41\u001b[0m 45ms/step - accuracy: 0.5522 - loss: 1.4435\n",
      "Final do lote 25000, Loss do lote: 1.3846473693847656\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava a coisa crescer.\n",
      "podou suboís ficar o\n",
      "senhor, dese\n",
      "\n",
      "\u001b[1m26000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3:56\u001b[0m 45ms/step - accuracy: 0.5529 - loss: 1.4413\n",
      "Final do lote 26000, Loss do lote: 1.383140206336975\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava lhe não\n",
      "contigeros com complemento; está perdeu. n\n",
      "\n",
      "\u001b[1m27000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3:19\u001b[0m 47ms/step - accuracy: 0.5536 - loss: 1.4391\n",
      "Final do lote 27000, Loss do lote: 1.381434679031372\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava por termo\n",
      "provar temporaira! delica que, à lei, se\n",
      "\n",
      "\u001b[1m28000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2:33\u001b[0m 47ms/step - accuracy: 0.5542 - loss: 1.4370\n",
      "Final do lote 28000, Loss do lote: 1.3796459436416626\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava de\n",
      "alcmena.\n",
      "\n",
      "o mesmo\n",
      "louvor de meia contrária dos \n",
      "\n",
      "\u001b[1m29000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1:46\u001b[0m 47ms/step - accuracy: 0.5548 - loss: 1.4350\n",
      "Final do lote 29000, Loss do lote: 1.3776590824127197\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava em filg ínatuação de lanjeda.\n",
      "verbo de que me apre\n",
      "\n",
      "\u001b[1m29999/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m58s\u001b[0m 47ms/step - accuracy: 0.5554 - loss: 1.4330\n",
      "Final do lote 30000, Loss do lote: 1.3751885890960693\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava na ensino contirbelativare; a vítima de acho aram!\n",
      "\n",
      "\u001b[1m31000/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.5560 - loss: 1.4311\n",
      "Final do lote 31000, Loss do lote: 1.3725049495697021\n",
      "\n",
      "--> Original text:  A menina estava \n",
      "--> Generated text:  A menina estava ocorrêncio ao charutárir brasileiro (cena político\n",
      "\n",
      "\u001b[1m31245/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5561 - loss: 1.4306Final da época 9, Loss: 1.3718143701553345, Acc: 0.5737341642379761\n",
      "\u001b[1m31246/31246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1506s\u001b[0m 48ms/step - accuracy: 0.5561 - loss: 1.4306 - val_accuracy: 0.5251 - val_loss: 1.5990\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "history_train = model.fit(train_set, \n",
    "                    validation_data=valid_set, \n",
    "                    epochs=10,\n",
    "                    callbacks=[LogCallback(history=history),\n",
    "                    model_ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
